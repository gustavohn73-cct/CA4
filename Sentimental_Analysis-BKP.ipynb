{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d62e489-97ee-4bbb-b586-dd0ac317d74c",
   "metadata": {},
   "source": [
    "# Requeriments"
   ]
  },
  {
   "cell_type": "raw",
   "id": "433947a5-27f6-4ef4-bc42-56beef670ceb",
   "metadata": {
    "tags": []
   },
   "source": [
    "!pip install textblob\n",
    "!pip install vaderSentiment\n",
    "!pip install nltk\n",
    "!pip install opendatasets\n",
    "!pip install textblob\n",
    "!pip install vaderSentiment\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c679a17-f94f-410d-8896-dd846235aa3f",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "66eb792e-231f-4d79-9c5a-dc8cd1442db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "#Spark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer, StopWordsRemover\n",
    "\n",
    "from pyspark.sql.functions import from_utc_timestamp, udf, array_distinct, col, when\n",
    "from pyspark.sql.functions import regexp_replace, year, month, dayofmonth, format_string\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "\n",
    "#Sentiment Analyzer\n",
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5ec793-ac24-4fb0-aff0-1e6b4e613d2b",
   "metadata": {},
   "source": [
    "### Imports with downloads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9f8a2d-7a9b-4127-a7bf-1bc4aad46376",
   "metadata": {},
   "source": [
    "This section is seperate just to prevent re-donwload the libraries which time a new library is add."
   ]
  },
  {
   "cell_type": "raw",
   "id": "754eaeb9-7f66-4398-81ea-fb18b7a270a5",
   "metadata": {},
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import string\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1369c9-74b3-48a7-9fb3-0bf35fc55299",
   "metadata": {},
   "source": [
    "### Warnings conf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e22943-ba31-4eb5-b6e1-7f73dc104bf8",
   "metadata": {},
   "source": [
    "In this sections the warnings are suppressed, less logs while running the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c9a2026-e856-49e6-887e-3785b04ed00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppressing the warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc46987-087c-4635-aaa0-dbedb9d4be30",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bee1cb-6ae4-4ee7-8517-b7fe7845658c",
   "metadata": {},
   "source": [
    "## Reading Data from Hadoop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ee164f-f374-49de-a701-753d1848ddd0",
   "metadata": {},
   "source": [
    "In this section we are reading data from Hadoop, using a Spark Session."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed403b96-9f0f-46c1-922e-189b8ad1d25e",
   "metadata": {},
   "source": [
    "### Spark configurations and Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bda5d84f-37a4-4cc3-928e-395faa4c23c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-11 18:44:32,831 WARN util.Utils: Your hostname, BDS-2023 resolves to a loopback address: 127.0.1.1; using 192.168.0.110 instead (on interface wlo1)\n",
      "2023-05-11 18:44:32,832 WARN util.Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "2023-05-11 18:44:33,858 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Configuration parameters for Spark\n",
    "spark_conf = SparkConf().setMaster(\"local[*]\").setAppName(\"HadoopAccess\")\n",
    "\n",
    "# Using SparkSession\n",
    "spark = SparkSession.builder.config(conf=spark_conf).config('spark.sql.session.timeZone', 'UTC').getOrCreate()\n",
    "\n",
    " # this will help not to have too much error displaying\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a1f8b4-d7f5-495e-b6c2-0758ef72ec01",
   "metadata": {},
   "source": [
    "### Tweets Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0874e98-5c18-4908-9525-fe3e714963c4",
   "metadata": {},
   "source": [
    "This dataset was collect from Internet Archive, processed and stored on hadoop, following the Collect Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0899f708-5738-4eef-8d24-af43af5dfbe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+--------------------+--------------------+\n",
      "|         created_at|month|                text|            entities|\n",
      "+-------------------+-----+--------------------+--------------------+\n",
      "|2022-01-01 23:51:54|    1|RT @ampahcd: @Zac...|\"{\\\"hashtags\\\": [...|\n",
      "|2022-01-01 23:41:24|    1|RT @Rina_The_Espe...|\"{\\\"hashtags\\\": [...|\n",
      "|2022-01-01 23:41:28|    1|@VVitchStreams @R...|\"{\\\"hashtags\\\": [...|\n",
      "+-------------------+-----+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Reading all parquets file in the folder tweets on Hadoop\n",
    "tweets = spark.read.parquet(\"/CA4/tweets/*.parquet\")\n",
    "\n",
    "#selecting just the columns wich we'll use in this analyse\n",
    "tweets = tweets.select(\"created_at\", \"month\", \"text\", \"entities\")\n",
    "\n",
    "#setting the column created_at as timestamp\n",
    "tweets = tweets.withColumn(\"created_at\", from_utc_timestamp(tweets[\"created_at\"], \"UTC\"))\n",
    "tweets.show(truncate=True, n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78d0e9b-ab6e-4c06-9a36-1d52973db94b",
   "metadata": {},
   "source": [
    "#### Exploring tweets Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8880f017-c1eb-41d8-a5f3-7eebcbf9010c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- created_at: timestamp (nullable = true)\n",
      " |-- month: long (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- entities: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweets.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab52d051-f9c6-49fc-b010-1637bbdf84a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:============================================>              (6 + 2) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+--------------------+--------------------+\n",
      "|summary|            month|                text|            entities|\n",
      "+-------+-----------------+--------------------+--------------------+\n",
      "|  count|           763266|              763266|              763266|\n",
      "|   mean|6.986469985562045|                null|                null|\n",
      "| stddev|4.225819505260059|                null|                null|\n",
      "|    min|                1|!\\nNew big data s...|\"{\\\"hashtags\\\": [...|\n",
      "|    25%|                2|                null|                null|\n",
      "|    50%|                7|                null|                null|\n",
      "|    75%|               11|                null|                null|\n",
      "|    max|               12|🫰💰💵\\n\\nRT @OAN...|{\"urls\": [{\"url\":...|\n",
      "+-------+-----------------+--------------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#as shown in the summary the dataframe has 763.266 lines\n",
    "tweets.summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "375665b7-3650-4bb8-a070-3ad82a5276b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+------+----------+\n",
      "|year|month| count|percentage|\n",
      "+----+-----+------+----------+\n",
      "|2021|   11|130286|    17.07%|\n",
      "|2021|   12|144352|    18.91%|\n",
      "|2022|    1|127260|    16.67%|\n",
      "|2022|    2| 67213|     8.81%|\n",
      "|2022|    3| 40585|     5.32%|\n",
      "|2022|    4| 31546|     4.13%|\n",
      "|2022|    5| 39132|     5.13%|\n",
      "|2022|    6| 38449|     5.04%|\n",
      "|2022|    7| 41471|     5.43%|\n",
      "|2022|    8| 32139|     4.21%|\n",
      "|2022|    9| 24553|     3.22%|\n",
      "|2022|   10| 46280|     6.06%|\n",
      "+----+-----+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#checking the distribution of tweets by month\n",
    "df = tweets.groupBy(year(\"created_at\").alias(\"year\"), month(\"created_at\").alias(\"month\")).count() \\\n",
    "                                 .orderBy([\"year\", \"month\"])\n",
    "#getting percentage\n",
    "df.withColumn(\"percentage\", format_string(\"%.2f%%\",((df[\"count\"]/tweets.count())*100))).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c5897b-276f-465a-9bd2-e5853bd79363",
   "metadata": {},
   "source": [
    "### Training Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165254b1-d4f9-491b-8249-4930c2574b34",
   "metadata": {},
   "source": [
    "Our model will be trained using a Dataset provided by user ardianumam on [Github](https://github.com/ardianumam/compilations/blob/master/ApacheSparkVideoSeries/dataset/README.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "185c4e2d-0dbe-49df-85b1-cc5e659c0738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                text|label|\n",
      "+--------------------+-----+\n",
      "|that film is fant...|    1|\n",
      "|this music is rea...|    1|\n",
      "|winter is terribl...|    0|\n",
      "+--------------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#read csv file\n",
    "tweets_train = spark.read.csv('/CA4/tweets/training_database/tweets.csv', inferSchema=True, header=True)\n",
    "tweets_train = tweets_train.select(col(\"SentimentText\").alias(\"text\"), col(\"Sentiment\").cast(\"Int\").alias(\"label\"))\n",
    "tweets_train.show(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1713ffb0-269c-43bc-b3d7-571760823580",
   "metadata": {},
   "source": [
    "#### Exploring training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b427dcf9-4584-4ac8-8b99-0dd7e9a67ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- text: string (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweets_train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18a7dbc6-d264-4ee6-9594-7eb8eda1eaba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+-------------------+\n",
      "|summary|                text|              label|\n",
      "+-------+--------------------+-------------------+\n",
      "|  count|                1932|               1932|\n",
      "|   mean|                null|0.49585921325051757|\n",
      "| stddev|                null|  0.500112298992253|\n",
      "|    min|I adore cheese #b...|                  0|\n",
      "|    25%|                null|                  0|\n",
      "|    50%|                null|                  0|\n",
      "|    75%|                null|                  1|\n",
      "|    max|winter is the bes...|                  1|\n",
      "+-------+--------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweets_train.summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae5aaa33-f83e-4f6d-8461-89c690618749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+----------+\n",
      "|label|count|percentage|\n",
      "+-----+-----+----------+\n",
      "|    1|  958|    49.59%|\n",
      "|    0|  974|    50.41%|\n",
      "+-----+-----+----------+\n",
      "\n",
      "Positive = 1\n",
      "Negative = 2\n"
     ]
    }
   ],
   "source": [
    "df = tweets_train.groupBy(\"label\").count()\n",
    "\n",
    "#getting percentage\n",
    "df.withColumn(\"percentage\", format_string(\"%.2f%%\",((df[\"count\"]/tweets_train.count())*100))).show()\n",
    "\n",
    "print(\"Positive = 1\")\n",
    "print(\"Negative = 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9218e2-bda0-41d8-b751-57198eb6f095",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843b40bb-5be7-4823-8371-fe8eb1a2e473",
   "metadata": {},
   "source": [
    "## Logistic Regression Classifier Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5877be-06ad-4266-bc0e-900095b0ad9a",
   "metadata": {},
   "source": [
    "Following the steps of the [tutorial](https://github.com/ardianumam/compilations/blob/master/ApacheSparkVideoSeries/08%20Sentiment%20Analysis%20in%20Spark.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070a4da1-c3b9-405a-b48d-d3dcb697e4c8",
   "metadata": {},
   "source": [
    "### Training Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1501127a-cbc1-4431-ae7e-2f38b7c28363",
   "metadata": {},
   "source": [
    "#### Dividing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f93251f1-9a79-4ba1-8471-fcaa6e685ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 1557 \n",
      "Testing: 375\n"
     ]
    }
   ],
   "source": [
    "#80% training, 20% testing\n",
    "dividedData = tweets_train.randomSplit([0.8, 0.2]) \n",
    "trainingData = dividedData[0] #index 0 = data training\n",
    "testingData = dividedData[1] #index 1 = data testing\n",
    "print (\"Training:\", trainingData.count(), \"\\nTesting:\", testingData.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcee83c-13d8-44b0-be84-983c7fbbca0e",
   "metadata": {},
   "source": [
    "#### Preparing Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f991f36-8940-4dc2-8b40-9cffac0be70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+\n",
      "|label|     MeaningfulWords|            features|\n",
      "+-----+--------------------+--------------------+\n",
      "|    1|[adore, cheese, #...|(262144,[1689,910...|\n",
      "|    1|[adore, cheese, #...|(262144,[1689,453...|\n",
      "|    1|[adore, cheese, #...|(262144,[1689,100...|\n",
      "+-----+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "tokenizedTrain = tokenizer.transform(trainingData)\n",
    "\n",
    "\n",
    "swr = StopWordsRemover(inputCol=tokenizer.getOutputCol(), \n",
    "                       outputCol=\"MeaningfulWords\")\n",
    "SwRemovedTrain = swr.transform(tokenizedTrain)\n",
    "\n",
    "\n",
    "hashTF = HashingTF(inputCol=swr.getOutputCol(), outputCol=\"features\")  \n",
    "numericTrainData = hashTF.transform(SwRemovedTrain).select(\n",
    "    'label', 'MeaningfulWords', 'features')\n",
    "\n",
    "numericTrainData.show(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b40264c-04d3-4fe0-89d0-2c54798d3911",
   "metadata": {},
   "source": [
    "#### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9db9a43c-9c6c-453b-8dc0-088380ffa77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is done!\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\", \n",
    "                        maxIter=10, regParam=0.01)\n",
    "model = lr.fit(numericTrainData)\n",
    "print (\"Training is done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72688d44-0600-43a4-bcbd-c8974d2232e7",
   "metadata": {},
   "source": [
    "#### Preparing Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c28a35f-0504-42aa-8db4-a707a6b57362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------------------+-------------------------------------------+\n",
      "|Label|MeaningfulWords            |features                                   |\n",
      "+-----+---------------------------+-------------------------------------------+\n",
      "|1    |[adore, cheese, #loveit]   |(262144,[1689,100089,254974],[1.0,1.0,1.0])|\n",
      "|1    |[adore, cheese, #toptastic]|(262144,[1689,42010,100089],[1.0,1.0,1.0]) |\n",
      "+-----+---------------------------+-------------------------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizedTest = tokenizer.transform(testingData)\n",
    "SwRemovedTest = swr.transform(tokenizedTest)\n",
    "numericTest = hashTF.transform(SwRemovedTest).select(\n",
    "    'Label', 'MeaningfulWords', 'features')\n",
    "numericTest.show(truncate=False, n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a08ddfb-47ca-45e0-8dff-33d16c989a86",
   "metadata": {},
   "source": [
    "#### Predicting testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d75699ee-2da0-45a6-85a7-48ed2b89a96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------+----------+-----+\n",
      "|MeaningfulWords                      |prediction|Label|\n",
      "+-------------------------------------+----------+-----+\n",
      "|[adore, cheese, #loveit]             |1.0       |1    |\n",
      "|[adore, cheese, #toptastic]          |1.0       |1    |\n",
      "|[adore, classical, music, #brilliant]|1.0       |1    |\n",
      "|[adore, classical, music, #thumbs-up]|1.0       |1    |\n",
      "+-------------------------------------+----------+-----+\n",
      "only showing top 4 rows\n",
      "\n",
      "Correct prediction: 371\n",
      "Total data: 375\n",
      "Accuracy: 0.9893\n"
     ]
    }
   ],
   "source": [
    "prediction = model.transform(numericTest)\n",
    "\n",
    "predictionFinal = prediction.select(\n",
    "    \"MeaningfulWords\", \"prediction\", \"Label\")\n",
    "\n",
    "predictionFinal.show(n=4, truncate = False)\n",
    "\n",
    "correctPrediction = predictionFinal.filter(predictionFinal['prediction'] == predictionFinal['Label']).count()\n",
    "\n",
    "totalData = predictionFinal.count()\n",
    "\n",
    "print(\"Correct prediction:\", correctPrediction) \n",
    "print(\"Total data:\", totalData)\n",
    "print(f\"Accuracy: {correctPrediction/totalData:.4}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ce784f-d80a-4d83-a490-153a8594c034",
   "metadata": {},
   "source": [
    "### Tweets Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d489388-87a9-474f-9cc9-893ebba6cb98",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8083a11e-7bbb-4a03-adaf-00c0e90a1af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+--------------------+--------------------+--------------------+\n",
      "|         created_at|month|                text|            entities|        cleaned_text|\n",
      "+-------------------+-----+--------------------+--------------------+--------------------+\n",
      "|2022-01-01 23:51:54|    1|RT @ampahcd: @Zac...|\"{\\\"hashtags\\\": [...| We are blowing l...|\n",
      "|2022-01-01 23:41:24|    1|RT @Rina_The_Espe...|\"{\\\"hashtags\\\": [...| Vaccine aparthei...|\n",
      "|2022-01-01 23:41:28|    1|@VVitchStreams @R...|\"{\\\"hashtags\\\": [...| You have no prob...|\n",
      "|2022-01-01 23:52:58|    1|RT @drmeenalviz: ...|\"{\\\"hashtags\\\": [...| To round off 202...|\n",
      "|2022-01-01 23:53:11|    1|RT @JacobEdwardIn...|\"{\\\"hashtags\\\": [...| Im Covid positiv...|\n",
      "+-------------------+-----+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "at_regex = r\"@\\w+\" #Remove usernames\n",
    "link_regex = r\"http\\S+\" #Remove links\n",
    "rt_regex = r'\\bRT\\b' #Remove 'RT'\n",
    "ss_regex = r'[^\\w\\s]' #Remove Special strings\n",
    "ds_regex = r'\\s+' #remove spaces\n",
    "\n",
    "tweets = tweets.withColumn(\"cleaned_text\", regexp_replace(\"text\", at_regex, \"\").alias(\"text_without_at_signs\")) \\\n",
    "    .withColumn(\"cleaned_text\", regexp_replace(\"cleaned_text\", link_regex, \"\").alias(\"text_without_links\")) \\\n",
    "    .withColumn(\"cleaned_text\", regexp_replace(\"cleaned_text\", rt_regex, \"\").alias(\"text_without_regex\")) \\\n",
    "    .withColumn(\"cleaned_text\", regexp_replace(\"cleaned_text\", ss_regex, \"\").alias(\"text_without_regex\")) \\\n",
    "    .withColumn(\"cleaned_text\", regexp_replace(\"cleaned_text\", ds_regex, \" \").alias(\"text_without_regex\"))\n",
    "\n",
    "tweets.show(n=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a78ef98-f37f-4e39-8020-8da518cb57d6",
   "metadata": {},
   "source": [
    "#### Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad4c6cf2-dc86-4e8c-8c0f-e037e3e685dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|     MeaningfulWords|            features|\n",
      "+--------------------+--------------------+\n",
      "|[, blowing, large...|(262144,[3928,510...|\n",
      "|[, vaccine, apart...|(262144,[32890,57...|\n",
      "|[, problem, injec...|(262144,[31536,76...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"cleaned_text\", outputCol=\"words\")\n",
    "tokenizedData = tokenizer.transform(tweets)\n",
    "\n",
    "swr = StopWordsRemover(inputCol=tokenizer.getOutputCol(), \n",
    "                       outputCol=\"MeaningfulWords\")\n",
    "SwRemoved = swr.transform(tokenizedData)\n",
    "\n",
    "hashTF = HashingTF(inputCol=swr.getOutputCol(), outputCol=\"features\")\n",
    "numericData = hashTF.transform(SwRemoved).select('MeaningfulWords', 'features')\n",
    "\n",
    "\n",
    "numericData.show(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cb9af7-57b1-4394-a73b-f40fc7079fb1",
   "metadata": {},
   "source": [
    "#### Predicting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b5dfaa4-ff29-4d54-9d34-b5aabfb38dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.transform(numericData)\n",
    "\n",
    "predictionFinal = prediction.select(\n",
    "    \"MeaningfulWords\", \"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f07893f3-18d1-41a8-926c-0e373a06f7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------+----------+\n",
      "|MeaningfulWords                                                                                             |prediction|\n",
      "+------------------------------------------------------------------------------------------------------------+----------+\n",
      "|[, blowing, large, holes, entire, pandemic, vaccination, agendabig, pharma]                                 |0.0       |\n",
      "|[, vaccine, apartheid, actually, exists, even, imperial, core, keep, mind]                                  |0.0       |\n",
      "|[, problem, injected, completely, unproven, vaccine, still, go]                                             |0.0       |\n",
      "|[, round, 2021, mum, bumped, old, friend, street, told, us, wouldnt, take, vaccine, amp, im]                |0.0       |\n",
      "|[, im, covid, positive, receiving, moderna, vaccines, im, still, able, show, work, er, based, cdc]          |0.0       |\n",
      "|[, youre, protesting, pfizers, covid, vaccine, still, popping, viagra, made, pfizer, makes, hypocrite, happ]|0.0       |\n",
      "|[, three, debacles, cards, far, high, incidence, severe, side, effects, possibility, vaccines, ge]          |0.0       |\n",
      "|[, religion, opposes, vaccines]                                                                             |0.0       |\n",
      "|[, choice, weigh, risks, vaccine, worked, great, concern]                                                   |1.0       |\n",
      "|[, la, county, incredibly, strict, vaccine, passports, worlds, longest, mask, mandates, stop]               |0.0       |\n",
      "+------------------------------------------------------------------------------------------------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictionFinal.show(truncate = False, n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67e0bbc-d9b5-4811-92e9-16387fa9f526",
   "metadata": {},
   "source": [
    "#### Join Prediction with Tweets Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f63182a-f628-45b2-b31f-526e98ee5603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "763266"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictionFinal.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312545a6-dba9-415f-bec9-fecaa4eef71d",
   "metadata": {},
   "source": [
    "As the forecast dataframe is following the tweet dataframe, it is possible to combine the two through an autoincremented index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9259ed3d-b7c9-4bc9-a805-3df242dcf7ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 57:==================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+--------------------+-----+----------+\n",
      "|         created_at|                text|        cleaned_text|month|prediction|\n",
      "+-------------------+--------------------+--------------------+-----+----------+\n",
      "|2022-01-01 23:51:54|RT @ampahcd: @Zac...| We are blowing l...|    1|       0.0|\n",
      "|2022-01-01 23:37:00|@ruiz20059 No.  W...| No What religion...|    1|       0.0|\n",
      "|2022-01-01 23:59:51|RT @WSJ: Internat...| International tr...|    1|       0.0|\n",
      "|2022-01-01 23:45:39|RT @toadmeister: ...| A major study fr...|    1|       0.0|\n",
      "|2022-01-01 23:46:11|@doctor_oxford Nu...| Nurses are too b...|    1|       0.0|\n",
      "|2022-01-01 23:46:38|RT @Madisontx76: ...| Why do Democrats...|    1|       0.0|\n",
      "|2022-01-01 23:29:36|RT @JasonLehn: If...| If you think hav...|    1|       1.0|\n",
      "|2022-01-01 23:12:57|RT @cooperlund: I...| It may seem like...|    1|       1.0|\n",
      "|2022-01-01 23:31:00|@7NewsSydney She ...| She doesnt seem ...|    1|       0.0|\n",
      "|2022-01-01 23:49:33|RT @gedkearney: N...| New year Same pr...|    1|       0.0|\n",
      "|2022-01-01 22:56:00|RT @SquireforBran...| My reserve of Si...|    1|       0.0|\n",
      "|2022-01-01 23:42:59|RT @birgitomo: Mu...| Must read Thread...|    1|       0.0|\n",
      "|2022-01-01 23:39:13|@kceelake ✝️Ameri...| American Heart J...|    1|       0.0|\n",
      "|2022-01-01 23:38:17|RT @JacobEdwardIn...| Im Covid positiv...|    1|       0.0|\n",
      "|2022-01-01 23:38:33|@tammysingley13 @...| I think he means...|    1|       0.0|\n",
      "|2022-01-01 22:42:55|RT @FurlongMick: ...| When it comes to...|    1|       0.0|\n",
      "|2022-01-01 23:33:32|RT @txsalth2o: Si...| Sincere question...|    1|       0.0|\n",
      "|2022-01-01 22:31:42|RT @Undergroundco...| Those medical mi...|    1|       0.0|\n",
      "|2022-01-01 22:36:56|RT @JesseKellyDC:...| 5 In one of the ...|    1|       0.0|\n",
      "|2022-01-01 23:25:48|RT @JesseKellyDC:...| 5 In one of the ...|    1|       0.0|\n",
      "+-------------------+--------------------+--------------------+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Create a column with id following the data's order \n",
    "tweets = tweets.withColumn(\"row_id\", monotonically_increasing_id())\n",
    "predictionFinal = predictionFinal.withColumn(\"row_id\", monotonically_increasing_id())\n",
    "\n",
    "# join by \"row_id\"\n",
    "tweets_pred = tweets.select('row_id','created_at', 'text', 'cleaned_text', 'month') \\\n",
    "                .join(predictionFinal.select('row_id', 'prediction'), \"row_id\", \"inner\")\n",
    "\n",
    "# drop column \n",
    "tweets_pred = tweets_pred.drop(\"row_id\")\n",
    "\n",
    "tweets_pred.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2712df-1a95-46b3-8657-64cdf4af2723",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Textblob and Varder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "25e1527d-ebf1-4be5-af50-fd49a5b8967b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions\n",
    "def f_textblob(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "def f_vader(text):\n",
    "    return SentimentIntensityAnalyzer().polarity_scores(text)['compound']\n",
    "\n",
    "\n",
    "#UDFs\n",
    "udf_textblob = udf(f_textblob, StringType())\n",
    "\n",
    "udf_vader = udf(f_vader, StringType())\n",
    "\n",
    "\n",
    "#applying to Dataframe\n",
    "tweets_pred = tweets_pred.withColumn(\"textblob\", udf_textblob(tweets_pred[\"cleaned_text\"])) \\\n",
    "                         .withColumn(\"vader\", udf_vader(tweets_pred[\"cleaned_text\"]))\n",
    "\n",
    "#tweets_pred_2.show(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de4b5f7-00af-4d6e-80b6-e7f41d147b2a",
   "metadata": {},
   "source": [
    "### Saving on Hadoop"
   ]
  },
  {
   "cell_type": "raw",
   "id": "63149c03-faf5-4113-a1fb-4aa9a1ec71df",
   "metadata": {},
   "source": [
    "#Last execution output:\n",
    "#CPU times: user 224 ms, sys: 156 ms, total: 380 ms\n",
    "#Wall time: 24min 21s\n",
    "\n",
    "%%time\n",
    "\n",
    "tweets_pred.write.partitionBy(\"month\").parquet(\"/CA4/predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f2b2d8ec-d23b-4e28-8547-391e1ad6146d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 65:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+--------------------+-----+----------+-------------------+------+\n",
      "|         created_at|                text|        cleaned_text|month|prediction|           textblob| vader|\n",
      "+-------------------+--------------------+--------------------+-----+----------+-------------------+------+\n",
      "|2022-01-01 23:51:54|RT @ampahcd: @Zac...| We are blowing l...|    1|       0.0|0.10714285714285714|   0.0|\n",
      "|2022-01-01 23:37:00|@ruiz20059 No.  W...| No What religion...|    1|       0.0|                0.0|-0.296|\n",
      "+-------------------+--------------------+--------------------+-----+----------+-------------------+------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "tweets_pred.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5193a215-e549-4b89-b6fe-48dfb6b37f1e",
   "metadata": {},
   "source": [
    "## DistilBert For Sequence Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df0bebb-5795-4539-b815-f7779e669594",
   "metadata": {},
   "source": [
    "Model from Huggingface for more information: [Model Documention](https://huggingface.co/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ed465e0a-85d9-4fff-9d53-e0d42645b730",
   "metadata": {},
   "source": [
    "classifier_sa = pipeline(\"sentiment-analysis\")\n",
    "#https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3ea36dd7-390a-4668-8106-810813c9406c",
   "metadata": {},
   "source": [
    "def f_classifier(text):\n",
    "    return 1 if classifier_sa(text)[0]['label'] == 'POSITIVE' else 0\n",
    "\n",
    "\n",
    "#UDFs\n",
    "udf_classifier = udf(f_classifier, StringType())\n",
    "\n",
    "#applying to Dataframe\n",
    "tweets_pred = tweets_pred.withColumn(\"classifier\", udf_classifier(tweets_pred[\"cleaned_text\"]))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0fa30d49-6eae-42b6-99e6-56a600c8305a",
   "metadata": {},
   "source": [
    "tweets_pred.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32ff454-3d85-4033-9cfb-090cb6766fa5",
   "metadata": {},
   "source": [
    "## Making our Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c947491-bacf-46d5-9962-f1c15afe2f35",
   "metadata": {},
   "source": [
    "The Score was calculated taking into account that Varder and TextBlob are tools developed for this type of analysis, they were given a weight of 1.5, the other analyzes had a weight of 1 out of a total of 5. In this way, it will be indicated as positive (1) if it is greater than zero otherwise it will be negative (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b71ae047-7fbc-47cd-912d-578ff9e82ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_pred = tweets_pred.withColumn(\"score\", ((col(\"prediction\") + (col(\"textblob\")*1.5) + (col(\"vader\")*1.5) + col(\"classifier\")) / 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ef97f793-5263-405a-a601-de23c4327720",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-11 19:54:11.941459: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-11 19:54:13.381652: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-11 19:54:13.381790: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-11 19:54:13.381803: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "[Stage 95:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+--------------------+-----+----------+--------------------+-------+----------+--------------------+\n",
      "|         created_at|                text|        cleaned_text|month|prediction|            textblob|  vader|classifier|               score|\n",
      "+-------------------+--------------------+--------------------+-----+----------+--------------------+-------+----------+--------------------+\n",
      "|2022-01-01 23:51:54|RT @ampahcd: @Zac...| We are blowing l...|    1|       0.0| 0.10714285714285714|    0.0|         0| 0.03214285714285714|\n",
      "|2022-01-01 23:37:00|@ruiz20059 No.  W...| No What religion...|    1|       0.0|                 0.0| -0.296|         0|-0.08879999999999999|\n",
      "|2022-01-01 23:59:51|RT @WSJ: Internat...| International tr...|    1|       0.0| 0.04545454545454545|    0.0|         1| 0.21363636363636362|\n",
      "|2022-01-01 23:45:39|RT @toadmeister: ...| A major study fr...|    1|       0.0|             0.03125|-0.4939|         0|           -0.138795|\n",
      "|2022-01-01 23:46:11|@doctor_oxford Nu...| Nurses are too b...|    1|       0.0|                -0.2|    0.0|         0|-0.06000000000000001|\n",
      "|2022-01-01 23:46:38|RT @Madisontx76: ...| Why do Democrats...|    1|       0.0|                 0.2|-0.6115|         0|-0.12345000000000002|\n",
      "|2022-01-01 23:29:36|RT @JasonLehn: If...| If you think hav...|    1|       1.0|                 0.0| 0.3612|         0|             0.30836|\n",
      "|2022-01-01 23:12:57|RT @cooperlund: I...| It may seem like...|    1|       1.0|-0.16666666666666666| 0.1127|         0| 0.18380999999999997|\n",
      "|2022-01-01 23:31:00|@7NewsSydney She ...| She doesnt seem ...|    1|       0.0|  0.4666666666666667|    0.0|         0| 0.13999999999999999|\n",
      "|2022-01-01 23:49:33|RT @gedkearney: N...| New year Same pr...|    1|       0.0| 0.03409090909090909|-0.6369|         0|-0.18084272727272727|\n",
      "+-------------------+--------------------+--------------------+-----+----------+--------------------+-------+----------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "tweets_pred.show(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2974ca9-522c-4ca4-9a5c-f23c8ae5b141",
   "metadata": {},
   "source": [
    "# Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bee8f651-24e8-4d97-ab33-65825ac0e088",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'day' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_72158/4208209222.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m                         .groupBy(year(\"created_at\").alias(\"year\"), \n\u001b[1;32m      3\u001b[0m                                  \u001b[0mmonth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"created_at\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"month\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                                  day(\"created_at\").alias(\"day\")) \\\n\u001b[0m\u001b[1;32m      5\u001b[0m                         \u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                         \u001b[0;34m.\u001b[0m\u001b[0morderBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"year\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"month\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"day\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'day' is not defined"
     ]
    }
   ],
   "source": [
    "tweets_fc = tweets_pred.select(\"created_at\", \"score\") \\\n",
    "                        .groupBy(year(\"created_at\").alias(\"year\"), \n",
    "                                 month(\"created_at\").alias(\"month\"),\n",
    "                                 day(\"created_at\").alias(\"day\")) \\\n",
    "                        .mean(\"score\") \\\n",
    "                        .orderBy([\"year\", \"month\", \"day\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63d04f1-a44b-4a56-97d8-4a99bc7603f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d500497f-02ac-4001-9f77-e3fdadaad867",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa68ca7-0235-43c2-8932-7bb1c2228971",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4e5a29-3978-4bbe-9a16-1440d71913eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056b7071-4b78-40f3-bd6d-abbe82a332c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a2a100-137c-44d3-a047-239d7722128d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c074e890-62a3-4fb1-8b87-f7366a1e292c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe7ff2f-3908-4066-b587-e924c4bee822",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1521a583-46a3-4b5e-928a-02778fcd6bb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c75ce8-1b42-4f67-adf1-74644649becf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1488d4f-ff64-447c-b285-d3e3f0ec14e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bea7cc-5e7f-43d2-9ae8-d6efff173068",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50506dfd-cd6a-4b07-bf90-b2a24974e4b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470af766-5bba-4fb8-9751-ead6b9e76b38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dfc26e-bba5-4939-93e2-42177dac0427",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bedea9d-2dfa-464a-b8d9-994fd8222a84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5bcdf9-9d70-4f54-bdd4-7e9951564b94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c98f3f-0766-46db-9e79-277a5c1390c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859a1f49-2dbb-49f4-9a31-da7d6459304b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dd771c-8df4-405a-bae7-5c980c30c826",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6bc462-6a8f-47ce-8c73-c43eef5bf0ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91e5b76-19cc-414e-a661-245a08202191",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f61d142-ad16-4d63-b2aa-c4cb62741e57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ea3beb9-6cba-46e1-be2b-2444c5eeee9d",
   "metadata": {},
   "source": [
    "#### Accessing Metadata"
   ]
  },
  {
   "cell_type": "raw",
   "id": "787c8527-187b-4878-a1c9-97aeff7ba1ee",
   "metadata": {},
   "source": [
    "import json\n",
    "\n",
    "json_obj = json.loads(pred['entities'][2])\n",
    "json_obj\n",
    "#print(json_obj['user_mentions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8737e270-bca1-4d11-8d0e-d91615b9b2ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d62e489-97ee-4bbb-b586-dd0ac317d74c",
   "metadata": {},
   "source": [
    "# Requeriments"
   ]
  },
  {
   "cell_type": "raw",
   "id": "433947a5-27f6-4ef4-bc42-56beef670ceb",
   "metadata": {
    "tags": []
   },
   "source": [
    "!pip install textblob\n",
    "!pip install vaderSentiment\n",
    "!pip install nltk\n",
    "!pip install opendatasets\n",
    "!pip install textblob\n",
    "!pip install vaderSentiment\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d3ac23-51d8-475e-a0c5-11f9f3fe3ab7",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c679a17-f94f-410d-8896-dd846235aa3f",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66eb792e-231f-4d79-9c5a-dc8cd1442db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 21:14:04.656134: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-10 21:14:09.931514: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-10 21:14:09.931912: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-10 21:14:09.931926: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import from_utc_timestamp, udf, array_distinct, col\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer, StopWordsRemover\n",
    "from tqdm.notebook import tqdm\n",
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5ec793-ac24-4fb0-aff0-1e6b4e613d2b",
   "metadata": {},
   "source": [
    "### Imports with downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5402eac-9314-4af1-a421-75ea6a1397cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/hduser/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import string\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1369c9-74b3-48a7-9fb3-0bf35fc55299",
   "metadata": {},
   "source": [
    "### Warnings conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c9a2026-e856-49e6-887e-3785b04ed00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppressing the warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bee1cb-6ae4-4ee7-8517-b7fe7845658c",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21a2d88a-8986-45cb-87bf-8ab49f51b472",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 21:14:16,758 WARN util.Utils: Your hostname, BDS-2023 resolves to a loopback address: 127.0.1.1; using 192.168.0.110 instead (on interface wlo1)\n",
      "2023-05-10 21:14:16,761 WARN util.Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "2023-05-10 21:14:18,158 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "#reading the data on Hadoop\n",
    "\n",
    "spark = SparkSession.builder.appName(\"HadoopAccess\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f358134-f61f-4974-aeab-f8f608f022e7",
   "metadata": {},
   "source": [
    "## ML on Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843b40bb-5be7-4823-8371-fe8eb1a2e473",
   "metadata": {},
   "source": [
    "### Creating a classifier model using training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c5897b-276f-465a-9bd2-e5853bd79363",
   "metadata": {},
   "source": [
    "#### Getting the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165254b1-d4f9-491b-8249-4930c2574b34",
   "metadata": {},
   "source": [
    "Dataset available [link](https://github.com/ardianumam/compilations/blob/master/ApacheSparkVideoSeries/dataset/README.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "185c4e2d-0dbe-49df-85b1-cc5e659c0738",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                text|label|\n",
      "+--------------------+-----+\n",
      "|that film is fant...|    1|\n",
      "|this music is rea...|    1|\n",
      "|winter is terribl...|    0|\n",
      "+--------------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#read csv file\n",
    "tweets_csv = spark.read.csv('/CA4/tweets/training_database/tweets.csv', inferSchema=True, header=True)\n",
    "tweets_csv = tweets_csv.select(col(\"SentimentText\").alias(\"text\"), col(\"Sentiment\").cast(\"Int\").alias(\"label\"))\n",
    "tweets_csv.show(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1501127a-cbc1-4431-ae7e-2f38b7c28363",
   "metadata": {},
   "source": [
    "#### Dividing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f93251f1-9a79-4ba1-8471-fcaa6e685ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 1557 ; Testing: 375\n"
     ]
    }
   ],
   "source": [
    "#80% training, 20% testing\n",
    "dividedData = tweets_csv.randomSplit([0.8, 0.2]) \n",
    "trainingData = dividedData[0] #index 0 = data training\n",
    "testingData = dividedData[1] #index 1 = data testing\n",
    "print (\"Training:\", trainingData.count(), \"; Testing:\", testingData.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcee83c-13d8-44b0-be84-983c7fbbca0e",
   "metadata": {},
   "source": [
    "#### Preparing Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f991f36-8940-4dc2-8b40-9cffac0be70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+\n",
      "|label|     MeaningfulWords|            features|\n",
      "+-----+--------------------+--------------------+\n",
      "|    1|[adore, cheese, #...|(262144,[1689,910...|\n",
      "|    1|[adore, cheese, #...|(262144,[1689,100...|\n",
      "|    1|[adore, cheese, #...|(262144,[1689,100...|\n",
      "+-----+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "tokenizedTrain = tokenizer.transform(trainingData)\n",
    "\n",
    "\n",
    "swr = StopWordsRemover(inputCol=tokenizer.getOutputCol(), \n",
    "                       outputCol=\"MeaningfulWords\")\n",
    "SwRemovedTrain = swr.transform(tokenizedTrain)\n",
    "\n",
    "\n",
    "hashTF = HashingTF(inputCol=swr.getOutputCol(), outputCol=\"features\")  \n",
    "numericTrainData = hashTF.transform(SwRemovedTrain).select(\n",
    "    'label', 'MeaningfulWords', 'features')\n",
    "\n",
    "numericTrainData.show(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b40264c-04d3-4fe0-89d0-2c54798d3911",
   "metadata": {},
   "source": [
    "#### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9db9a43c-9c6c-453b-8dc0-088380ffa77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 21:14:35,505 WARN netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "2023-05-10 21:14:35,505 WARN netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is done!\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\", \n",
    "                        maxIter=10, regParam=0.01)\n",
    "model = lr.fit(numericTrainData)\n",
    "print (\"Training is done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72688d44-0600-43a4-bcbd-c8974d2232e7",
   "metadata": {},
   "source": [
    "#### Preparing Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c28a35f-0504-42aa-8db4-a707a6b57362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------------------+------------------------------------------+\n",
      "|Label|MeaningfulWords            |features                                  |\n",
      "+-----+---------------------------+------------------------------------------+\n",
      "|1    |[adore, cheese, #brilliant]|(262144,[1689,45361,100089],[1.0,1.0,1.0])|\n",
      "|1    |[adore, cheese, #thumbs-up]|(262144,[1689,88825,100089],[1.0,1.0,1.0])|\n",
      "+-----+---------------------------+------------------------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizedTest = tokenizer.transform(testingData)\n",
    "SwRemovedTest = swr.transform(tokenizedTest)\n",
    "numericTest = hashTF.transform(SwRemovedTest).select(\n",
    "    'Label', 'MeaningfulWords', 'features')\n",
    "numericTest.show(truncate=False, n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a08ddfb-47ca-45e0-8dff-33d16c989a86",
   "metadata": {},
   "source": [
    "#### Predicting testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d75699ee-2da0-45a6-85a7-48ed2b89a96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------+----------+-----+\n",
      "|MeaningfulWords                      |prediction|Label|\n",
      "+-------------------------------------+----------+-----+\n",
      "|[adore, cheese, #brilliant]          |1.0       |1    |\n",
      "|[adore, cheese, #thumbs-up]          |1.0       |1    |\n",
      "|[adore, classical, music, #brilliant]|1.0       |1    |\n",
      "|[adore, jam, #toptastic]             |1.0       |1    |\n",
      "+-------------------------------------+----------+-----+\n",
      "only showing top 4 rows\n",
      "\n",
      "Correct prediction: 370\n",
      "Total data: 375\n",
      "Accuracy: 0.9867\n"
     ]
    }
   ],
   "source": [
    "prediction = model.transform(numericTest)\n",
    "\n",
    "predictionFinal = prediction.select(\n",
    "    \"MeaningfulWords\", \"prediction\", \"Label\")\n",
    "\n",
    "predictionFinal.show(n=4, truncate = False)\n",
    "\n",
    "correctPrediction = predictionFinal.filter(predictionFinal['prediction'] == predictionFinal['Label']).count()\n",
    "\n",
    "totalData = predictionFinal.count()\n",
    "\n",
    "print(\"Correct prediction:\", correctPrediction) \n",
    "print(\"Total data:\", totalData)\n",
    "print(f\"Accuracy: {correctPrediction/totalData:.4}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ce784f-d80a-4d83-a490-153a8594c034",
   "metadata": {},
   "source": [
    "### Processing data collected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0899f708-5738-4eef-8d24-af43af5dfbe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 31:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+--------------------+--------------------+\n",
      "|         created_at|month|                text|            entities|\n",
      "+-------------------+-----+--------------------+--------------------+\n",
      "|2022-01-01 23:51:54|    1|RT @ampahcd: @Zac...|\"{\\\"hashtags\\\": [...|\n",
      "|2022-01-01 23:41:24|    1|RT @Rina_The_Espe...|\"{\\\"hashtags\\\": [...|\n",
      "|2022-01-01 23:41:28|    1|@VVitchStreams @R...|\"{\\\"hashtags\\\": [...|\n",
      "+-------------------+-----+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Setting timestamp\n",
    "df = spark.read.parquet(\"/CA4/tweets/*.parquet\")\n",
    "df = df.select(\"created_at\", \"month\", \"text\", \"entities\")\n",
    "df = df.withColumn(\"created_at\", from_utc_timestamp(df[\"created_at\"], \"UTC\"))\n",
    "df.show(truncate=True, n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d489388-87a9-474f-9cc9-893ebba6cb98",
   "metadata": {},
   "source": [
    "#### Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8083a11e-7bbb-4a03-adaf-00c0e90a1af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+--------------------+--------------------+--------------------+\n",
      "|         created_at|month|                text|            entities|        cleaned_text|\n",
      "+-------------------+-----+--------------------+--------------------+--------------------+\n",
      "|2022-01-01 23:51:54|    1|RT @ampahcd: @Zac...|\"{\\\"hashtags\\\": [...| We are blowing l...|\n",
      "|2022-01-01 23:41:24|    1|RT @Rina_The_Espe...|\"{\\\"hashtags\\\": [...| Vaccine aparthei...|\n",
      "|2022-01-01 23:41:28|    1|@VVitchStreams @R...|\"{\\\"hashtags\\\": [...| You have no prob...|\n",
      "|2022-01-01 23:52:58|    1|RT @drmeenalviz: ...|\"{\\\"hashtags\\\": [...| To round off 202...|\n",
      "|2022-01-01 23:53:11|    1|RT @JacobEdwardIn...|\"{\\\"hashtags\\\": [...| Im Covid positiv...|\n",
      "|2022-01-01 23:53:30|    1|RT @LakotaMan1: I...|\"{\\\"hashtags\\\": [...| If youre protest...|\n",
      "|2022-01-01 23:08:54|    1|RT @luigi_warren:...|\"{\\\"hashtags\\\": [...| So three debacle...|\n",
      "|2022-01-01 23:37:00|    1|@ruiz20059 No.  W...|\"{\\\"hashtags\\\": [...| No What religion...|\n",
      "|2022-01-01 23:37:03|    1|@oiler3535 @led21...|\"{\\\"hashtags\\\": [...| Its our choice a...|\n",
      "|2022-01-01 23:37:06|    1|RT @ianmSC: LA Co...|\"{\\\"hashtags\\\": [...| LA County We hav...|\n",
      "|2022-01-01 23:37:08|    1|Over 1.4cr adoles...|\"{\\\"hashtags\\\": [...|Over 14cr adolesc...|\n",
      "|2022-01-01 23:37:25|    1|@piersmorgan Paid...|\"{\\\"hashtags\\\": [...| Paid for promoti...|\n",
      "|2022-01-01 23:37:29|    1|RT @gedkearney: N...|\"{\\\"hashtags\\\": [...| New year Same pr...|\n",
      "|2022-01-01 23:37:45|    1|Local hospital’s ...|\"{\\\"hashtags\\\": [...|Local hospitals c...|\n",
      "|2022-01-01 23:23:22|    1|RT @realKyleKeega...|\"{\\\"hashtags\\\": [...| If you have reli...|\n",
      "|2022-01-01 23:59:23|    1|RT @NordicNomadEs...|\"{\\\"hashtags\\\": [...| The purpose of l...|\n",
      "|2022-01-01 23:59:24|    1|@TedCasey12 @thre...|\"{\\\"hashtags\\\": [...| I dont understan...|\n",
      "|2022-01-01 23:59:34|    1|RT @SteveEls1: @G...|\"{\\\"hashtags\\\": [...| Another virus cr...|\n",
      "|2022-01-01 23:59:50|    1|RT @stkirsch: My ...|\"{\\\"hashtags\\\": [...| My secret plan t...|\n",
      "|2022-01-01 23:59:51|    1|RT @WSJ: Internat...|\"{\\\"hashtags\\\": [...| International tr...|\n",
      "+-------------------+-----+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import regexp_replace\n",
    "\n",
    "at_regex = r\"@\\w+\" #Remove usernames\n",
    "link_regex = r\"http\\S+\" #Remove links\n",
    "rt_regex = r'\\bRT\\b' #Remove 'RT'\n",
    "ss_regex = r'[^\\w\\s]' #Remove Special strings\n",
    "ds_regex = r'\\s+' #remove spaces\n",
    "\n",
    "tweets = df.withColumn(\"cleaned_text\", regexp_replace(\"text\", at_regex, \"\").alias(\"text_without_at_signs\")) \\\n",
    "    .withColumn(\"cleaned_text\", regexp_replace(\"cleaned_text\", link_regex, \"\").alias(\"text_without_links\")) \\\n",
    "    .withColumn(\"cleaned_text\", regexp_replace(\"cleaned_text\", rt_regex, \"\").alias(\"text_without_regex\")) \\\n",
    "    .withColumn(\"cleaned_text\", regexp_replace(\"cleaned_text\", ss_regex, \"\").alias(\"text_without_regex\")) \\\n",
    "    .withColumn(\"cleaned_text\", regexp_replace(\"cleaned_text\", ds_regex, \" \").alias(\"text_without_regex\"))\n",
    "\n",
    "#tweets = tweets.select(\"cleaned_text\")\n",
    "\n",
    "tweets.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a78ef98-f37f-4e39-8020-8da518cb57d6",
   "metadata": {},
   "source": [
    "#### Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad4c6cf2-dc86-4e8c-8c0f-e037e3e685dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|     MeaningfulWords|            features|\n",
      "+--------------------+--------------------+\n",
      "|[, blowing, large...|(262144,[3928,510...|\n",
      "|[, vaccine, apart...|(262144,[32890,57...|\n",
      "|[, problem, injec...|(262144,[31536,76...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"cleaned_text\", outputCol=\"words\")\n",
    "tokenizedData = tokenizer.transform(tweets)\n",
    "\n",
    "swr = StopWordsRemover(inputCol=tokenizer.getOutputCol(), \n",
    "                       outputCol=\"MeaningfulWords\")\n",
    "SwRemoved = swr.transform(tokenizedData)\n",
    "\n",
    "hashTF = HashingTF(inputCol=swr.getOutputCol(), outputCol=\"features\")\n",
    "numericData = hashTF.transform(SwRemoved).select('MeaningfulWords', 'features')\n",
    "\n",
    "\n",
    "numericData.show(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cb9af7-57b1-4394-a73b-f40fc7079fb1",
   "metadata": {},
   "source": [
    "#### Predicting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b5dfaa4-ff29-4d54-9d34-b5aabfb38dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.transform(numericData)\n",
    "\n",
    "predictionFinal = prediction.select(\n",
    "    \"MeaningfulWords\", \"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f07893f3-18d1-41a8-926c-0e373a06f7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------------------------------+----------+\n",
      "|MeaningfulWords                                                                                                             |prediction|\n",
      "+----------------------------------------------------------------------------------------------------------------------------+----------+\n",
      "|[, blowing, large, holes, entire, pandemic, vaccination, agendabig, pharma]                                                 |0.0       |\n",
      "|[, vaccine, apartheid, actually, exists, even, imperial, core, keep, mind]                                                  |0.0       |\n",
      "|[, problem, injected, completely, unproven, vaccine, still, go]                                                             |0.0       |\n",
      "|[, round, 2021, mum, bumped, old, friend, street, told, us, wouldnt, take, vaccine, amp, im]                                |0.0       |\n",
      "|[, im, covid, positive, receiving, moderna, vaccines, im, still, able, show, work, er, based, cdc]                          |0.0       |\n",
      "|[, youre, protesting, pfizers, covid, vaccine, still, popping, viagra, made, pfizer, makes, hypocrite, happ]                |0.0       |\n",
      "|[, three, debacles, cards, far, high, incidence, severe, side, effects, possibility, vaccines, ge]                          |0.0       |\n",
      "|[, religion, opposes, vaccines]                                                                                             |0.0       |\n",
      "|[, choice, weigh, risks, vaccine, worked, great, concern]                                                                   |1.0       |\n",
      "|[, la, county, incredibly, strict, vaccine, passports, worlds, longest, mask, mandates, stop]                               |0.0       |\n",
      "|[14cr, adolescents, eligible, covid19, vaccine]                                                                             |0.0       |\n",
      "|[, paid, promoting, vaccine, isnt, ah, bless]                                                                               |0.0       |\n",
      "|[, new, year, problem, last, year, morrison, government, didnt, order, enough, vaccines, exposed]                           |0.0       |\n",
      "|[local, hospitals, chief, medical, officer, got, covid19, christmas, urges, vaccination]                                    |0.0       |\n",
      "|[, religious, objections, getting, vaccine, new, years, resolution, needs, find, new, religion]                             |0.0       |\n",
      "|[, purpose, lockdowns, ready, scale, healthcare, systems, eradicate, covid, purpose, vaccines, wa]                          |0.0       |\n",
      "|[, dont, understand, vaccines, work, vaccines, work]                                                                        |0.0       |\n",
      "|[, another, virus, created, vaccines, isreal, nearly, 100, vaccinated, boosted, one, flu]                                   |0.0       |\n",
      "|[, secret, plan, end, vaccine, madness]                                                                                     |0.0       |\n",
      "|[, international, travel, bumpy, new, digital, tools, keep, track, covid, vaccination, info, testing, requirements, attempt]|0.0       |\n",
      "+----------------------------------------------------------------------------------------------------------------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictionFinal.show(truncate = False, n=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67e0bbc-d9b5-4811-92e9-16387fa9f526",
   "metadata": {},
   "source": [
    "#### Join Prediction with Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f63182a-f628-45b2-b31f-526e98ee5603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "763266"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictionFinal.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9259ed3d-b7c9-4bc9-a805-3df242dcf7ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 44:==================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+--------------------+-----+----------+\n",
      "|         created_at|                text|        cleaned_text|month|prediction|\n",
      "+-------------------+--------------------+--------------------+-----+----------+\n",
      "|2022-01-01 23:51:54|RT @ampahcd: @Zac...| We are blowing l...|    1|       0.0|\n",
      "|2022-01-01 23:37:00|@ruiz20059 No.  W...| No What religion...|    1|       0.0|\n",
      "|2022-01-01 23:59:51|RT @WSJ: Internat...| International tr...|    1|       0.0|\n",
      "|2022-01-01 23:45:39|RT @toadmeister: ...| A major study fr...|    1|       0.0|\n",
      "|2022-01-01 23:46:11|@doctor_oxford Nu...| Nurses are too b...|    1|       0.0|\n",
      "|2022-01-01 23:46:38|RT @Madisontx76: ...| Why do Democrats...|    1|       0.0|\n",
      "|2022-01-01 23:29:36|RT @JasonLehn: If...| If you think hav...|    1|       1.0|\n",
      "|2022-01-01 23:12:57|RT @cooperlund: I...| It may seem like...|    1|       1.0|\n",
      "|2022-01-01 23:31:00|@7NewsSydney She ...| She doesnt seem ...|    1|       0.0|\n",
      "|2022-01-01 23:49:33|RT @gedkearney: N...| New year Same pr...|    1|       0.0|\n",
      "|2022-01-01 22:56:00|RT @SquireforBran...| My reserve of Si...|    1|       0.0|\n",
      "|2022-01-01 23:42:59|RT @birgitomo: Mu...| Must read Thread...|    1|       0.0|\n",
      "|2022-01-01 23:39:13|@kceelake ✝️Ameri...| American Heart J...|    1|       0.0|\n",
      "|2022-01-01 23:38:17|RT @JacobEdwardIn...| Im Covid positiv...|    1|       0.0|\n",
      "|2022-01-01 23:38:33|@tammysingley13 @...| I think he means...|    1|       0.0|\n",
      "|2022-01-01 22:42:55|RT @FurlongMick: ...| When it comes to...|    1|       0.0|\n",
      "|2022-01-01 23:33:32|RT @txsalth2o: Si...| Sincere question...|    1|       0.0|\n",
      "|2022-01-01 22:31:42|RT @Undergroundco...| Those medical mi...|    1|       0.0|\n",
      "|2022-01-01 22:36:56|RT @JesseKellyDC:...| 5 In one of the ...|    1|       0.0|\n",
      "|2022-01-01 23:25:48|RT @JesseKellyDC:...| 5 In one of the ...|    1|       0.0|\n",
      "+-------------------+--------------------+--------------------+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "\n",
    "# Create a column with id following the data's order \n",
    "tweets = tweets.withColumn(\"row_id\", monotonically_increasing_id())\n",
    "predictionFinal = predictionFinal.withColumn(\"row_id\", monotonically_increasing_id())\n",
    "\n",
    "# join by \"row_id\"\n",
    "tweets_pred = tweets.select('row_id','created_at', 'text', 'cleaned_text', 'month') \\\n",
    "                .join(predictionFinal.select('row_id', 'prediction'), \"row_id\", \"inner\")\n",
    "\n",
    "# drop column \n",
    "tweets_pred = tweets_pred.drop(\"row_id\")\n",
    "\n",
    "tweets_pred.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2712df-1a95-46b3-8657-64cdf4af2723",
   "metadata": {},
   "source": [
    "### Textblob and Varder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25e1527d-ebf1-4be5-af50-fd49a5b8967b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions\n",
    "def f_textblob(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "def f_vader(text):\n",
    "    return SentimentIntensityAnalyzer().polarity_scores(text)['compound']\n",
    "\n",
    "\n",
    "#UDFs\n",
    "udf_textblob = udf(f_textblob, StringType())\n",
    "\n",
    "udf_vader = udf(f_vader, StringType())\n",
    "\n",
    "\n",
    "#applying to Dataframe\n",
    "tweets_pred = tweets_pred.withColumn(\"textblob\", udf_textblob(tweets_pred[\"cleaned_text\"])) \\\n",
    "                         .withColumn(\"vader\", udf_vader(tweets_pred[\"cleaned_text\"]))\n",
    "\n",
    "#tweets_pred_2.show(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f5f600bb-d572-4d9d-a112-1acdc7787e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 224 ms, sys: 156 ms, total: 380 ms\n",
      "Wall time: 24min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tweets_pred.write.partitionBy(\"month\").parquet(\"/CA4/predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f2b2d8ec-d23b-4e28-8547-391e1ad6146d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 57:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+--------------------+-----+----------+-------------------+------+\n",
      "|         created_at|                text|        cleaned_text|month|prediction|           textblob| vader|\n",
      "+-------------------+--------------------+--------------------+-----+----------+-------------------+------+\n",
      "|2022-01-01 23:51:54|RT @ampahcd: @Zac...| We are blowing l...|    1|       0.0|0.10714285714285714|   0.0|\n",
      "|2022-01-01 23:37:00|@ruiz20059 No.  W...| No What religion...|    1|       0.0|                0.0|-0.296|\n",
      "+-------------------+--------------------+--------------------+-----+----------+-------------------+------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 21:55:18,231 WARN python.PythonUDFRunner: Detected deadlock while completing task 0.0 in stage 57 (TID 115): Attempting to kill Python Worker\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "tweets_pred.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5193a215-e549-4b89-b6fe-48dfb6b37f1e",
   "metadata": {},
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de26a389-bca0-4f40-9bb0-d95230e38f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "classifier_sa = pipeline(\"sentiment-analysis\")\n",
    "#https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a576f4f7-1371-4350-a6fe-81aa814514e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_classifier(text):\n",
    "    return 1 if classifier_sa(text)[0]['label'] == 'POSITIVE' else 0\n",
    "\n",
    "\n",
    "#UDFs\n",
    "udf_classifier = udf(f_classifier, StringType())\n",
    "\n",
    "#applying to Dataframe\n",
    "tweets_pred = tweets_pred.withColumn(\"classifier\", udf_classifier(tweets_pred[\"cleaned_text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1737d27f-dd9f-4d6f-9dab-b3c4ea8d71ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 21:58:48.261706: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-10 21:58:49.058649: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-10 21:58:49.058718: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-10 21:58:49.058724: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "[Stage 62:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+--------------------+-----+----------+-------------------+------+----------+\n",
      "|         created_at|                text|        cleaned_text|month|prediction|           textblob| vader|classifier|\n",
      "+-------------------+--------------------+--------------------+-----+----------+-------------------+------+----------+\n",
      "|2022-01-01 23:51:54|RT @ampahcd: @Zac...| We are blowing l...|    1|       0.0|0.10714285714285714|   0.0|         0|\n",
      "|2022-01-01 23:37:00|@ruiz20059 No.  W...| No What religion...|    1|       0.0|                0.0|-0.296|         0|\n",
      "+-------------------+--------------------+--------------------+-----+----------+-------------------+------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "tweets_pred.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e634c8-4b85-423a-9fda-83cc41b233ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a23cca-0283-407a-b8b9-10d564b97b47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71ae047-7fbc-47cd-912d-578ff9e82ec3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cddf592-66b3-4773-9996-d5dbf09d93b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54232ead-4d8b-40fc-a1ec-8bb206c15658",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4748b2-ba07-433e-8d8b-bb4d6329c572",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8935bc2-9202-4cd5-abc6-e64069141e8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef97f793-5263-405a-a601-de23c4327720",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed650b2-a3bc-4368-9de0-e86a40f8399f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c967cfa5-6673-4f25-ad75-fd1c57d5bad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@delayed\n",
    "def text_blob_polarity(text):\n",
    "    return 2 if TextBlob(text).sentiment.polarity > 0 else 0\n",
    "\n",
    "@delayed\n",
    "def vader_polarity(text):\n",
    "    return 2 if SentimentIntensityAnalyzer().polarity_scores(text)['compound'] > 0 else 0\n",
    "\n",
    "@delayed\n",
    "def classifier_polarity(text):\n",
    "    return 1 if classifier_sa(text)[0]['label'] == 'POSITIVE' else 0\n",
    "\n",
    "@delayed\n",
    "def calculate_score(t,v,c,p):\n",
    "    return 1 if ((t + v + c + p)/4) >= 1 else 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "88eb9261-1c9a-409e-b84f-82d60e6e9410",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_dd['textBlob'] = tweets_dd['cleaned_text'].map(lambda text: text_blob_polarity(text))\n",
    "tweets_dd['vader'] = tweets_dd['cleaned_text'].map(lambda text: vader_polarity(text))\n",
    "tweets_dd['classifier'] = tweets_dd['cleaned_text'].map(lambda text: classifier_polarity(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e484ee4-36c9-4869-87a0-c785acce5825",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_dd.compute() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63d04f1-a44b-4a56-97d8-4a99bc7603f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d500497f-02ac-4001-9f77-e3fdadaad867",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa68ca7-0235-43c2-8932-7bb1c2228971",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4e5a29-3978-4bbe-9a16-1440d71913eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056b7071-4b78-40f3-bd6d-abbe82a332c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a2a100-137c-44d3-a047-239d7722128d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c074e890-62a3-4fb1-8b87-f7366a1e292c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe7ff2f-3908-4066-b587-e924c4bee822",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1521a583-46a3-4b5e-928a-02778fcd6bb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c75ce8-1b42-4f67-adf1-74644649becf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1488d4f-ff64-447c-b285-d3e3f0ec14e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bea7cc-5e7f-43d2-9ae8-d6efff173068",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "de4e0ad2-aa54-4361-95cb-8bd85bfffa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tweets_pd\n",
    "\n",
    "def calculate_score(row):\n",
    "    return 1 if ((row['classifier'] + row['vader'] + row['textBlob'] + row['prediction'])/4) >= 1 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ac9dfcaf-86e7-4e0d-ad8b-bfec76a8d96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['textBlob'] = df['cleaned_text'].apply(lambda x: 2 if TextBlob(x).sentiment.polarity > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d0cf4c-5d9d-4489-be4c-98f9e48f3bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vader'] = df['cleaned_text'].apply(lambda x: 2 if SentimentIntensityAnalyzer().polarity_scores(x)['compound'] > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f8a1b5-afa0-49ca-aeb1-161355e97328",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['classifier'] = df['cleaned_text'].apply(lambda x: 1 if classifier_sa(x)[0]['label'] == 'POSITIVE' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84793529-97ef-4567-8ad8-fe3b83e883b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['score'] = df.apply(calculate_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fe59cb7a-1fee-449c-83ec-304eaac7ba9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>prediction</th>\n",
       "      <th>textBlob</th>\n",
       "      <th>vader</th>\n",
       "      <th>classifier</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>249178</th>\n",
       "      <td>2022-03-22 23:08:55</td>\n",
       "      <td>RT @freethought202: 1. “Given the evidence of ...</td>\n",
       "      <td>1 Given the evidence of white cell depletion ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449573</th>\n",
       "      <td>2022-06-07 22:07:50</td>\n",
       "      <td>RT @USMortality: So the FDA members, stated, t...</td>\n",
       "      <td>So the FDA members stated that they are autho...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151726</th>\n",
       "      <td>2022-02-27 15:37:22</td>\n",
       "      <td>I hope vaccines are not mandatory by the time ...</td>\n",
       "      <td>I hope vaccines are not mandatory by the time ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725585</th>\n",
       "      <td>2022-06-10 18:08:32</td>\n",
       "      <td>The Biden administration is preparing to distr...</td>\n",
       "      <td>The Biden administration is preparing to distr...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704050</th>\n",
       "      <td>2022-02-09 00:26:40</td>\n",
       "      <td>This isn’t okay. Talking about a vaccine is. \\...</td>\n",
       "      <td>This isnt okay Talking about a vaccine is Chan...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558222</th>\n",
       "      <td>2022-09-11 20:25:58</td>\n",
       "      <td>RT @truedevonthomps: I’ve made up my mind. Tho...</td>\n",
       "      <td>Ive made up my mind Those still advocating fo...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625247</th>\n",
       "      <td>2022-10-20 03:39:08</td>\n",
       "      <td>RT @leezeldin: As Governor, I will oppose mand...</td>\n",
       "      <td>As Governor I will oppose mandating the COVID...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641925</th>\n",
       "      <td>2022-08-01 05:33:33</td>\n",
       "      <td>@MAGA_VIBES @FoxNews The freedom convoy agains...</td>\n",
       "      <td>The freedom convoy against the Mandatory Vacc...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337172</th>\n",
       "      <td>2022-02-15 23:18:23</td>\n",
       "      <td>RT @AndrewLawton: As more provinces do away wi...</td>\n",
       "      <td>As more provinces do away with vaccine passpo...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442737</th>\n",
       "      <td>2022-10-26 22:08:36</td>\n",
       "      <td>RT @JackPosobiec: THE VACCINES DO NOT STOP THE...</td>\n",
       "      <td>THE VACCINES DO NOT STOP THE SPREAD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603203</th>\n",
       "      <td>2021-11-19 15:11:15</td>\n",
       "      <td>RT @TheVoxWolf: So tribe...what will we all do...</td>\n",
       "      <td>So tribewhat will we all do when they make va...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151643</th>\n",
       "      <td>2022-02-26 05:42:42</td>\n",
       "      <td>@SteveSchmidtSES @ZelenskyyUa I bet he’s not t...</td>\n",
       "      <td>I bet hes not terrified of getting a lil vacc...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372863</th>\n",
       "      <td>2022-04-25 21:13:14</td>\n",
       "      <td>and before you even go there\\n\\nfree speech;\\n...</td>\n",
       "      <td>and before you even go there free speech i wil...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193115</th>\n",
       "      <td>2022-01-11 00:22:14</td>\n",
       "      <td>RT @Mikel_Jollett: SCIENTISTS: We developed a ...</td>\n",
       "      <td>SCIENTISTS We developed a vaccine which makes...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329487</th>\n",
       "      <td>2021-11-26 14:27:53</td>\n",
       "      <td>RT @joe_warmington: Scientists reject pundits'...</td>\n",
       "      <td>Scientists reject pundits vaccine theory afte...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                created_at                                               text  \\\n",
       "249178 2022-03-22 23:08:55  RT @freethought202: 1. “Given the evidence of ...   \n",
       "449573 2022-06-07 22:07:50  RT @USMortality: So the FDA members, stated, t...   \n",
       "151726 2022-02-27 15:37:22  I hope vaccines are not mandatory by the time ...   \n",
       "725585 2022-06-10 18:08:32  The Biden administration is preparing to distr...   \n",
       "704050 2022-02-09 00:26:40  This isn’t okay. Talking about a vaccine is. \\...   \n",
       "558222 2022-09-11 20:25:58  RT @truedevonthomps: I’ve made up my mind. Tho...   \n",
       "625247 2022-10-20 03:39:08  RT @leezeldin: As Governor, I will oppose mand...   \n",
       "641925 2022-08-01 05:33:33  @MAGA_VIBES @FoxNews The freedom convoy agains...   \n",
       "337172 2022-02-15 23:18:23  RT @AndrewLawton: As more provinces do away wi...   \n",
       "442737 2022-10-26 22:08:36  RT @JackPosobiec: THE VACCINES DO NOT STOP THE...   \n",
       "603203 2021-11-19 15:11:15  RT @TheVoxWolf: So tribe...what will we all do...   \n",
       "151643 2022-02-26 05:42:42  @SteveSchmidtSES @ZelenskyyUa I bet he’s not t...   \n",
       "372863 2022-04-25 21:13:14  and before you even go there\\n\\nfree speech;\\n...   \n",
       "193115 2022-01-11 00:22:14  RT @Mikel_Jollett: SCIENTISTS: We developed a ...   \n",
       "329487 2021-11-26 14:27:53  RT @joe_warmington: Scientists reject pundits'...   \n",
       "\n",
       "                                             cleaned_text  prediction  \\\n",
       "249178   1 Given the evidence of white cell depletion ...         0.0   \n",
       "449573   So the FDA members stated that they are autho...         0.0   \n",
       "151726  I hope vaccines are not mandatory by the time ...         0.0   \n",
       "725585  The Biden administration is preparing to distr...         0.0   \n",
       "704050  This isnt okay Talking about a vaccine is Chan...         0.0   \n",
       "558222   Ive made up my mind Those still advocating fo...         0.0   \n",
       "625247   As Governor I will oppose mandating the COVID...         0.0   \n",
       "641925   The freedom convoy against the Mandatory Vacc...         0.0   \n",
       "337172   As more provinces do away with vaccine passpo...         0.0   \n",
       "442737                THE VACCINES DO NOT STOP THE SPREAD         0.0   \n",
       "603203   So tribewhat will we all do when they make va...         0.0   \n",
       "151643   I bet hes not terrified of getting a lil vacc...         0.0   \n",
       "372863  and before you even go there free speech i wil...         0.0   \n",
       "193115   SCIENTISTS We developed a vaccine which makes...         0.0   \n",
       "329487   Scientists reject pundits vaccine theory afte...         0.0   \n",
       "\n",
       "        textBlob  vader  classifier  score  \n",
       "249178         0    NaN         NaN    NaN  \n",
       "449573         0    NaN         NaN    NaN  \n",
       "151726         0    NaN         NaN    NaN  \n",
       "725585         0    NaN         NaN    NaN  \n",
       "704050         2    NaN         NaN    NaN  \n",
       "558222         0    NaN         NaN    NaN  \n",
       "625247         0    NaN         NaN    NaN  \n",
       "641925         0    NaN         NaN    NaN  \n",
       "337172         2    NaN         NaN    NaN  \n",
       "442737         0    NaN         NaN    NaN  \n",
       "603203         0    NaN         NaN    NaN  \n",
       "151643         0    NaN         NaN    NaN  \n",
       "372863         2    NaN         NaN    NaN  \n",
       "193115         0    NaN         NaN    NaN  \n",
       "329487         0    NaN         NaN    NaN  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50506dfd-cd6a-4b07-bf90-b2a24974e4b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470af766-5bba-4fb8-9751-ead6b9e76b38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dfc26e-bba5-4939-93e2-42177dac0427",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bedea9d-2dfa-464a-b8d9-994fd8222a84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5bcdf9-9d70-4f54-bdd4-7e9951564b94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c98f3f-0766-46db-9e79-277a5c1390c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859a1f49-2dbb-49f4-9a31-da7d6459304b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dd771c-8df4-405a-bae7-5c980c30c826",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6bc462-6a8f-47ce-8c73-c43eef5bf0ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91e5b76-19cc-414e-a661-245a08202191",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f61d142-ad16-4d63-b2aa-c4cb62741e57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ea3beb9-6cba-46e1-be2b-2444c5eeee9d",
   "metadata": {},
   "source": [
    "#### Accessing Metadata"
   ]
  },
  {
   "cell_type": "raw",
   "id": "787c8527-187b-4878-a1c9-97aeff7ba1ee",
   "metadata": {},
   "source": [
    "import json\n",
    "\n",
    "json_obj = json.loads(pred['entities'][2])\n",
    "json_obj\n",
    "#print(json_obj['user_mentions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8737e270-bca1-4d11-8d0e-d91615b9b2ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

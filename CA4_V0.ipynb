{
 "cells": [
  {
   "cell_type": "raw",
   "id": "29dd464e-a654-4118-8cfb-743f936d12c8",
   "metadata": {},
   "source": [
    "!pip install internetarchive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "7b36d8b9-4b17-4bea-bbfd-a4beb7244d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import internetarchive\n",
    "import os\n",
    "import tarfile\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "cc07a036-7be4-41c0-92d4-c4f489a34a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def control_op(control_file):\n",
    "\n",
    "    #if file doesn't exist I'll create it\n",
    "    if not os.path.exists(control_file):\n",
    "        with open(control_file, 'w', newline='') as control_csv:\n",
    "            writer = csv.DictWriter(control_csv, fieldnames=['name','datetime'])\n",
    "            writer.writeheader()\n",
    "        control_csv.close()\n",
    "        print(\"{} created.\".format(control_file))\n",
    "            \n",
    "    #Reading the control file\n",
    "    with open(control_file, 'r', newline='') as control_csv:\n",
    "        reader = csv.DictReader(control_csv)\n",
    "        reader_data = [r for r in reader]\n",
    "        control_csv.seek(0)\n",
    "    control_csv.close()\n",
    "    \n",
    "    return reader_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "4887335f-3783-4a95-94c1-79c422c428f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_folder(name_folder):            \n",
    "    #Creating folder if that doesn't exist\n",
    "    p = %pwd\n",
    "    p = p + f'/{name_folder}'\n",
    "    path = os.path.expanduser(p)\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        print(\"{} created.\".format(path))\n",
    "        \n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "186417d1-fca8-4dcc-907e-da5c3591a4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_name(item_name, ext='*tar'):\n",
    "    \n",
    "    file_names = [f.name for f in internetarchive.get_files(item_name, glob_pattern= ext)]\n",
    "    \n",
    "    return file_names"
   ]
  },
  {
   "cell_type": "raw",
   "id": "920198c0-99f3-4c02-b330-dbd6a41e628c",
   "metadata": {},
   "source": [
    "def download_file(item_name, file_name, path):\n",
    "    \n",
    "    item = internetarchive.get_item(item_name)\n",
    "    \n",
    "    #Downloading\n",
    "    r = item.download(\n",
    "            destdir=path,  # The directory to download files to\n",
    "            ignore_existing=True,  # Skip files that already exist locally\n",
    "            checksum=True,  # Skip files based on checksum\n",
    "            verbose=True,  # Print progress to stdout\n",
    "            retries=100,  # The number of times to retry on failed requests\n",
    "            no_directory=True,  # Download withtout the identifier\n",
    "            files = file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "0502fcf3-2628-4ac4-b0d8-6145dac56060",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(item_name, file_name, download_folder = 'Downloads'):\n",
    "    \n",
    "    path = check_folder(download_folder)\n",
    "    \n",
    "    #calling function for getting control file\n",
    "    control_path = path + '/control_download.csv'    \n",
    "    reader_data = control_op(control_path)\n",
    "    \n",
    "    #Getteing Itens names\n",
    "    item = internetarchive.get_item(item_name)\n",
    "        \n",
    "    #openning control file to add file names on the list\n",
    "    with open(control_path, 'a', newline='') as control_download:\n",
    "        writer = csv.DictWriter(control_download, fieldnames=['name','datetime'])\n",
    "        \n",
    "        #check if the file has been downloaded before\n",
    "        if not any(row['name'] == file_name for row in reader_data):\n",
    "            \n",
    "            #downloading\n",
    "            r = item.download(\n",
    "                destdir=path,  # The directory to download files to\n",
    "                ignore_existing=True,  # Skip files that already exist locally\n",
    "                checksum=True,  # Skip files based on checksum\n",
    "                verbose=True,  # Print progress to stdout\n",
    "                retries=100,  # The number of times to retry on failed requests\n",
    "                no_directory=True,  # Download withtout the identifier\n",
    "                files = file_name)\n",
    "            \n",
    "            #Adding file name on control list\n",
    "            row = {'name' : t, 'datetime': datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "            writer.writerow(row)\n",
    "            \n",
    "    control_download.close()\n",
    "    \n",
    "    path_file = path + f'/{file_name}'\n",
    "    \n",
    "    return path_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "5ee9268d-0988-4248-9c72-bb22753af55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tar_file(tar_file, file_name, extration_folder='Extration'):\n",
    "\n",
    "    path = check_folder(extration_folder)\n",
    "    \n",
    "    tar = tar_file\n",
    "    \n",
    "    #calling function for getting control file\n",
    "    control_path = path + '/control_extraction.csv'    \n",
    "    reader_data = control_op(control_path)\n",
    "\n",
    "    #openning control file to add file names on the list\n",
    "    with open(control_path, 'a', newline='') as control_tar:\n",
    "        writer = csv.DictWriter(control_tar, fieldnames=['name','datetime'])\n",
    "        \n",
    "        #check if the file has been extrated before\n",
    "        if not any(row['name'] == file_name for row in reader_data):\n",
    "\n",
    "            #Extracting file\n",
    "            tar.extract(file_name, path=path)\n",
    "\n",
    "            #Saving files name on control file\n",
    "            row = {'name' : file_name, 'datetime': datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "            writer.writerow(row)\n",
    "    control_tar.close()\n",
    "    \n",
    "    path_file = path + f'/{file_name}'\n",
    "    \n",
    "    return path_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beaeee45-45c4-40ed-a224-1f768ec6c380",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_name = 'archiveteam-twitter-stream-2022-10'\n",
    "\n",
    "#Getteing Itens names\n",
    "file_names = get_file_name(item_name = item_name)#, ext = '*jpg')\n",
    "\n",
    "x = 0\n",
    "\n",
    "for dlf in tqdm(file_names, desc='Download progress'):\n",
    "    \n",
    "    if x < 1: #for testing \n",
    "        #downloading the file\n",
    "        file = download_file(item_name = item_name, file_name = dlf)\n",
    "\n",
    "        #Open tar file\n",
    "        tar = tarfile.open(file, \"r\")\n",
    "\n",
    "        #Getting json files' names\n",
    "        tar_file_names = list(filter(lambda t: t.endswith('.json.gz'), tar.getnames()))\n",
    "\n",
    "        for tf in tqdm(tar_file_names, desc='Unzip progress'):\n",
    "            js = tar_file(tar_file = tar, file_name = tf)\n",
    "            \n",
    "\n",
    "        tar.close()\n",
    "        \n",
    "        x =+ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "905e0112-4bf5-4550-a4c7-d4fa64ecd03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/home/hduser/Desktop/CA 2.2/Extration/20221001/20221001000000.json.gz'\n",
    "\n",
    "df = pd.read_json(file_path, lines=True, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "4672acb6-9aa9-4b5b-8921-e01045691769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3009 entries, 0 to 3008\n",
      "Data columns (total 37 columns):\n",
      " #   Column                     Non-Null Count  Dtype              \n",
      "---  ------                     --------------  -----              \n",
      " 0   created_at                 3009 non-null   datetime64[ns, UTC]\n",
      " 1   id                         3009 non-null   int64              \n",
      " 2   id_str                     3009 non-null   int64              \n",
      " 3   text                       3009 non-null   object             \n",
      " 4   display_text_range         945 non-null    object             \n",
      " 5   source                     3009 non-null   object             \n",
      " 6   truncated                  3009 non-null   bool               \n",
      " 7   in_reply_to_status_id      623 non-null    float64            \n",
      " 8   in_reply_to_status_id_str  623 non-null    float64            \n",
      " 9   in_reply_to_user_id        647 non-null    float64            \n",
      " 10  in_reply_to_user_id_str    647 non-null    float64            \n",
      " 11  in_reply_to_screen_name    647 non-null    object             \n",
      " 12  user                       3009 non-null   object             \n",
      " 13  geo                        1 non-null      object             \n",
      " 14  coordinates                1 non-null      object             \n",
      " 15  place                      14 non-null     object             \n",
      " 16  contributors               0 non-null      float64            \n",
      " 17  is_quote_status            3009 non-null   bool               \n",
      " 18  quote_count                3009 non-null   int64              \n",
      " 19  reply_count                3009 non-null   int64              \n",
      " 20  retweet_count              3009 non-null   int64              \n",
      " 21  favorite_count             3009 non-null   int64              \n",
      " 22  entities                   3009 non-null   object             \n",
      " 23  favorited                  3009 non-null   bool               \n",
      " 24  retweeted                  3009 non-null   bool               \n",
      " 25  filter_level               3009 non-null   object             \n",
      " 26  lang                       3009 non-null   object             \n",
      " 27  timestamp_ms               3009 non-null   datetime64[ns]     \n",
      " 28  extended_tweet             394 non-null    object             \n",
      " 29  retweeted_status           1332 non-null   object             \n",
      " 30  extended_entities          708 non-null    object             \n",
      " 31  possibly_sensitive         1123 non-null   float64            \n",
      " 32  quoted_status_id           193 non-null    float64            \n",
      " 33  quoted_status_id_str       193 non-null    float64            \n",
      " 34  quoted_status              193 non-null    object             \n",
      " 35  quoted_status_permalink    193 non-null    object             \n",
      " 36  withheld_in_countries      4 non-null      object             \n",
      "dtypes: bool(4), datetime64[ns, UTC](1), datetime64[ns](1), float64(8), int64(6), object(17)\n",
      "memory usage: 787.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "12e37500-3043-48aa-8403-3ac8f136f9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_data(file_path, word_bag, lang = 'en'):\n",
    "    \n",
    "    #reading json\n",
    "    df = pd.read_json(file_path, lines=True, compression='gzip')\n",
    "    \n",
    "    #Filtering language\n",
    "    df = df[df.lang == lang]\n",
    "    \n",
    "    #getting columns\n",
    "    df = df.loc[:, ['created_at', 'text']]\n",
    "    \n",
    "    #filtering Tweets using subject word bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "81d46bd0-df23-4fd4-84af-b03a94c1ec54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4 entries, 244 to 2267\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype              \n",
      "---  ------      --------------  -----              \n",
      " 0   created_at  4 non-null      datetime64[ns, UTC]\n",
      " 1   text        4 non-null      object             \n",
      "dtypes: datetime64[ns, UTC](1), object(1)\n",
      "memory usage: 96.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "bow = '|'.join(['vaccine', 'vac' ]) # bag of word\n",
    "df_f = df[df['text'].str.contains(bow, case=False)]\n",
    "df_f.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "450cd3ac-39e8-4885-8933-34e09b52d3ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @BinmyHeartinter: Bright Morning ⛅️ \\nStarting the 1st. day of October with a good news from Bright Vachirawit, who had the most follower…'"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_f.text[244]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5904c3-374d-43aa-9d3d-afb831cd377c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

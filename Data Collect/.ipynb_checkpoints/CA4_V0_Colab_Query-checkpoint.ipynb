{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7746b2f-415a-40d6-bff4-f168b99297f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "import os\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import configparser\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e74bfc3e-c7cc-40f6-91be-167d8790958e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppressing the warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb91bad8-a138-4684-adee-67d24eafb728",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_connection():\n",
    "\n",
    "    #getting configuration\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read('config.ini')\n",
    "\n",
    "    # Connect to Mysql\n",
    "    conn = mysql.connector.connect(\n",
    "        host = config['mysql']['host'],\n",
    "        user = config['mysql']['user'],\n",
    "        password = config['mysql']['password'],\n",
    "        database = config['mysql']['database']\n",
    "    )\n",
    "        \n",
    "    return conn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86983d1e-0a94-44d8-96ac-4d2c01325b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_folder(name_folder):            \n",
    "    #Creating folder if that doesn't exist\n",
    "    p = %pwd\n",
    "    p = p + f'/{name_folder}'\n",
    "    path = os.path.expanduser(p)\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        print(\"{} created.\".format(path))\n",
    "        \n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59bd68aa-eb6b-4977-a09a-2f041e93b121",
   "metadata": {},
   "outputs": [],
   "source": [
    "def humanize(size_bytes):\n",
    "    KB = 1 << 10\n",
    "    MB = 1 << 20\n",
    "    GB = 1 << 30\n",
    "\n",
    "    if size_bytes < KB:\n",
    "        return '{} B'.format(size_bytes)\n",
    "    elif size_bytes < MB:\n",
    "        return '{:.2f} KiB'.format(size_bytes/KB)\n",
    "    elif size_bytes < GB:\n",
    "        return '{:.2f} MiB'.format(size_bytes/MB)\n",
    "    else:\n",
    "        return '{:.2f} GiB'.format(size_bytes/GB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7503875-1216-4828-b79f-ddb3d9fcfaac",
   "metadata": {},
   "source": [
    "## Export Control"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134c32a1-f730-46ac-aea1-707af42036ca",
   "metadata": {},
   "source": [
    "### Get Info do Control CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef8a017a-d2d4-4350-9a53-c421152acba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of days: 31 \n",
      "\n",
      "Total Downloaded: 77.73 GiB\n",
      "An average of 2.51 GiB per day downloaded \n",
      "\n",
      "Total of Tweets: 120,699,166.0\n",
      "An average of 3,893,521 tweets downloaded per day \n",
      "\n",
      "Tweets filtered: 127,261.0\n",
      "An average of 4,105 tweets filtered per day \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>datetime</th>\n",
       "      <th>type</th>\n",
       "      <th>size</th>\n",
       "      <th>count_total</th>\n",
       "      <th>count_filtered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23016</th>\n",
       "      <td>20220117/20220117221500.json.gz</td>\n",
       "      <td>2023-05-05 22:30:58</td>\n",
       "      <td>extraction</td>\n",
       "      <td>1642654</td>\n",
       "      <td>2473.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  name             datetime        type  \\\n",
       "23016  20220117/20220117221500.json.gz  2023-05-05 22:30:58  extraction   \n",
       "\n",
       "          size  count_total  count_filtered  \n",
       "23016  1642654       2473.0             1.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_folder = check_folder('Downloads/202201')\n",
    "control_csv = (f'{download_folder}/control.csv')\n",
    "\n",
    "df = pd.read_csv(control_csv)\n",
    "df = df.fillna(value=0)\n",
    "\n",
    "down_df = df[df['name'].str.startswith('twitter')]\n",
    "ext_df= df[~df['name'].str.startswith('twitter')]\n",
    "\n",
    "\n",
    "ext_df['data'] = ext_df['name'].str[:8].apply(lambda x: datetime.strptime(x, '%Y%m%d').strftime('%Y-%m-%d'))\n",
    "ext_df['data'] = pd.to_datetime(ext_df['data'])\n",
    "ext_df['size'] = ext_df['size'].astype(float)\n",
    "ext_df['count_total'] = ext_df['count_total'].astype(float)\n",
    "ext_df['count_filtered'] = ext_df['count_filtered'].astype(float)\n",
    "\n",
    "\n",
    "donwloaded = ext_df.groupby(pd.Grouper(key='data', freq='M'))['size'].sum()\n",
    "print(f\"Total of days: {len(down_df)} \\n\")\n",
    "\n",
    "print(f\"Total Downloaded: {humanize(donwloaded.sum())}\")\n",
    "print(f\"An average of {humanize(donwloaded.sum()/len(down_df))} per day downloaded \\n\")\n",
    "\n",
    "print(\"Total of Tweets: {:,}\".format(df['count_total'].sum()))\n",
    "print(f\"An average of {ext_df['count_total'].sum()/len(down_df):,.0f} tweets downloaded per day \\n\")\n",
    "\n",
    "print(\"Tweets filtered: {:,}\".format(df['count_filtered'].sum()))\n",
    "print(f\"An average of {ext_df['count_filtered'].sum()/len(down_df):,.0f} tweets filtered per day \\n\")\n",
    "\n",
    "df.sample(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b649515-9ca9-4888-bc44-9ea772664198",
   "metadata": {},
   "source": [
    "### Insert into Mysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fbeda43c-d146-4750-8717-49ee11054e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 44368/44368 [00:22<00:00, 1940.35it/s]\n"
     ]
    }
   ],
   "source": [
    "conn = open_connection()\n",
    "cursor = conn.cursor()\n",
    "\n",
    "for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "    name = row['name']\n",
    "    datetime = row['datetime']\n",
    "    type_ = row['type']\n",
    "    size = row['size']\n",
    "    count_total = row['count_total']\n",
    "    count_filtered = row['count_filtered']\n",
    "    sql = \"INSERT INTO control (name, datetime, type, size, count_total, count_filtered) VALUES (%s, %s, %s, %s, %s, %s)\"\n",
    "    cursor.execute(sql, (name, datetime, type_, size, count_total, count_filtered))\n",
    "\n",
    "conn.commit()\n",
    "cursor.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b453918e-9621-493b-9589-2046a78d2fd8",
   "metadata": {},
   "source": [
    "## Export Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc5ee8db-bd51-48af-9f48-b563f7dd2859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of Tweets: 127,261 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53461</th>\n",
       "      <td>2022-01-13 22:00:03+00:00</td>\n",
       "      <td>RT @ToniaBuxton: How much more of this needs t...</td>\n",
       "      <td>{\"hashtags\": [], \"urls\": [], \"user_mentions\": ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      created_at  \\\n",
       "53461  2022-01-13 22:00:03+00:00   \n",
       "\n",
       "                                                    text  \\\n",
       "53461  RT @ToniaBuxton: How much more of this needs t...   \n",
       "\n",
       "                                                entities  \n",
       "53461  {\"hashtags\": [], \"urls\": [], \"user_mentions\": ...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_folder = check_folder('Downloads/202201')\n",
    "control_csv = (f'{download_folder}/202201_tweets.csv')\n",
    "\n",
    "df = pd.read_csv(control_csv)\n",
    "df = df.fillna(value=0)\n",
    "\n",
    "print(f\"Total of Tweets: {len(df):,} \\n\")\n",
    "\n",
    "df.sample(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43022914-15b2-4fa2-8840-b895faf878ef",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Insert on MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "29d2c37a-cdc3-41b7-99e5-e3b8ef5f24ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 127261/127261 [01:18<00:00, 1627.52it/s]\n"
     ]
    }
   ],
   "source": [
    "conn = open_connection()\n",
    "cursor = conn.cursor()\n",
    "\n",
    "for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "    created_at = row['created_at']\n",
    "    text = row['text']\n",
    "    entities = json.dumps(row['entities'])\n",
    "    sql = \"INSERT INTO tweets (created_at, text, entities) VALUES (%s, %s, %s)\"\n",
    "    cursor.execute(sql, (created_at, text, entities))\n",
    "\n",
    "conn.commit()\n",
    "cursor.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a3d9e3-8d8f-455e-ba6c-114e770bf97f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

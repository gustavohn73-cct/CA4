{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbfcb2a1-c76f-4c24-957e-9369c40ed719",
   "metadata": {},
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "raw",
   "id": "29dd464e-a654-4118-8cfb-743f936d12c8",
   "metadata": {},
   "source": [
    "!pip install internetarchive\n",
    "!pip install mysql-connector-python\n",
    "!pip install libtorrent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492d93c2-4b48-4cf7-a445-89db0a09a599",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b36d8b9-4b17-4bea-bbfd-a4beb7244d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import internetarchive\n",
    "import os\n",
    "import tarfile\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import configparser\n",
    "import mysql.connector\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e7c5cad-7e70-46e9-9484-0209505e912e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppressing the warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef408647-f9e9-448b-85ef-9f1772efb9c8",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480c9a17-78f2-4d93-8404-cddb59dd43c9",
   "metadata": {},
   "source": [
    "## General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4887335f-3783-4a95-94c1-79c422c428f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_folder(name_folder):            \n",
    "    #Creating folder if that doesn't exist\n",
    "    p = %pwd\n",
    "    p = p + f'/{name_folder}'\n",
    "    path = os.path.expanduser(p)\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        print(\"{} created.\".format(path))\n",
    "        \n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "186417d1-fca8-4dcc-907e-da5c3591a4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_name(item_name, ext='*tar'):\n",
    "    \n",
    "    file_names = [f.name for f in internetarchive.get_files(item_name, glob_pattern= ext)]\n",
    "    \n",
    "    return file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8224599-ab0a-43db-a4af-63ceaaaf5fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def humanize(size_bytes):\n",
    "    KB = 1 << 10\n",
    "    MB = 1 << 20\n",
    "    GB = 1 << 30\n",
    "\n",
    "    if size_bytes < KB:\n",
    "        return '{} B'.format(size_bytes)\n",
    "    elif size_bytes < MB:\n",
    "        return '{:.1f} KiB'.format(size_bytes/KB)\n",
    "    elif size_bytes < GB:\n",
    "        return '{:.1f} MiB'.format(size_bytes/MB)\n",
    "    else:\n",
    "        return '{:.1f} GiB'.format(size_bytes/GB)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a526cb-8bb0-4bdc-a383-b0e5841cab27",
   "metadata": {},
   "source": [
    "## Cleaning and Transfomations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12e37500-3043-48aa-8403-3ac8f136f9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(file_path, file_name, word_bag = False, lang = False, db_update = False):\n",
    "    \n",
    "    #reading json\n",
    "    df = pd.read_json(file_path, lines=True, compression='gzip')\n",
    "    \n",
    "    #updating total tweets\n",
    "    if not update_db == False:\n",
    "        update_db(table = 'control', field = f\"count_total = '{len(df)}'\", condition = f\"name = '{file_name}'\")\n",
    "    \n",
    "    #Filtering language if a language was sent\n",
    "    if not lang == False:\n",
    "        df = df[df.lang == lang]\n",
    "    \n",
    "    #taking away columns unnecessary\n",
    "    df = df.loc[:, ['created_at', 'text', 'entities']]\n",
    "    \n",
    "    #filtering Tweets using subject word bag if a word bag was sent\n",
    "    if not word_bag == False:\n",
    "        bow = '|'.join(word_bag) # bag of word\n",
    "        df = df[df['text'].str.contains(bow, case=False)]\n",
    "        \n",
    "        #updating filtered tweets\n",
    "        if not update_db == False:\n",
    "            update_db(table = 'control', field = f\"count_filtered = '{len(df)}'\", condition = f\"name = '{file_name}'\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3267d74a-1829-44cf-a53e-f0597320bf1d",
   "metadata": {},
   "source": [
    "## Control Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2af3344-6b81-4c18-a504-70041f78d9be",
   "metadata": {},
   "source": [
    "### CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc07a036-7be4-41c0-92d4-c4f489a34a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def control_op_csv(control_file):\n",
    "\n",
    "    #if file doesn't exist I'll create it\n",
    "    if not os.path.exists(control_file):\n",
    "        with open(control_file, 'w', newline='') as control_csv:\n",
    "            writer = csv.DictWriter(control_csv, fieldnames=['name','datetime'])\n",
    "            writer.writeheader()\n",
    "        control_csv.close()\n",
    "        print(\"{} created.\".format(control_file))\n",
    "            \n",
    "    #Reading the control file\n",
    "    with open(control_file, 'r', newline='') as control_csv:\n",
    "        reader = csv.DictReader(control_csv)\n",
    "        reader_data = [r for r in reader]\n",
    "        control_csv.seek(0)\n",
    "    control_csv.close()\n",
    "    \n",
    "    return reader_data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "857497e9-a0cf-4c51-ac3b-32b583edad21",
   "metadata": {},
   "source": [
    "path = check_folder('Downloads')\n",
    "\n",
    "#calling function for getting control file\n",
    "control_path = path + '/control_download.csv'    \n",
    "reader_data = control_op_csv(control_path)\n",
    "reader_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0502fcf3-2628-4ac4-b0d8-6145dac56060",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file_csv(item_name, file_name, download_folder = 'Downloads'):\n",
    "    \n",
    "    path = check_folder(download_folder)\n",
    "    \n",
    "    #calling function for getting control file\n",
    "    control_path = path + '/control_download.csv'    \n",
    "    reader_data = control_op_csv(control_path)\n",
    "    \n",
    "    #Getting Itens names\n",
    "    item = internetarchive.get_item(item_name)\n",
    "        \n",
    "    #openning control file to add file names on the list\n",
    "    with open(control_path, 'a', newline='') as control_download:\n",
    "        writer = csv.DictWriter(control_download, fieldnames=['name','datetime'])\n",
    "        \n",
    "        #check if the file has been downloaded before\n",
    "        if not any(row['name'] == file_name for row in reader_data):\n",
    "            \n",
    "            #downloading\n",
    "            r = item.download(\n",
    "                destdir=path,  # The directory to download files to\n",
    "                ignore_existing=True,  # Skip files that already exist locally\n",
    "                checksum=True,  # Skip files based on checksum\n",
    "                verbose=True,  # Print progress to stdout\n",
    "                retries=100,  # The number of times to retry on failed requests\n",
    "                no_directory=True,  # Download withtout the identifier\n",
    "                files = file_name)\n",
    "            \n",
    "            #Adding file name on control list\n",
    "            row = {'name' : file_name, 'datetime': datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "            writer.writerow(row)\n",
    "            \n",
    "    control_download.close()\n",
    "    \n",
    "    path_file = path + f'/{file_name}'\n",
    "    \n",
    "    return path_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ee9268d-0988-4248-9c72-bb22753af55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tar_file_csv(tar_file, file_name, extration_folder='Extraction'):\n",
    "\n",
    "    path = check_folder(extration_folder)\n",
    "    \n",
    "    #calling function for getting control file\n",
    "    control_path = path + '/control_extraction.csv'    \n",
    "    reader_data = control_op(control_path)\n",
    "\n",
    "    #openning control file to add file names on the list\n",
    "    with open(control_path, 'a', newline='') as control_tar:\n",
    "        writer = csv.DictWriter(control_tar, fieldnames=['name','datetime'])\n",
    "        \n",
    "        #check if the file has been extrated before\n",
    "        if not any(row['name'] == file_name for row in reader_data):\n",
    "\n",
    "            #Extracting file\n",
    "            tar_file.extract(file_name, path=path)\n",
    "\n",
    "            #Saving files name on control file\n",
    "            row = {'name' : file_name, 'datetime': datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "            writer.writerow(row)\n",
    "            \n",
    "            path_file = path + f'/{file_name}'\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            path_file = False\n",
    "    \n",
    "    control_tar.close()\n",
    "    \n",
    "    \n",
    "    return path_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530faf1b-3818-4358-90d1-2dc89ee170c8",
   "metadata": {},
   "source": [
    "### Mysql"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a6bc96-91f0-481b-b4bf-ab17cb3e0ba6",
   "metadata": {},
   "source": [
    "#### Basic operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51b47408-deae-439f-84ee-ce0e09139d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_connection():\n",
    "\n",
    "    #getting configuration\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read('config.ini')\n",
    "\n",
    "    # Connect to Mysql\n",
    "    conn = mysql.connector.connect(\n",
    "        host = config['mysql']['host'],\n",
    "        user = config['mysql']['user'],\n",
    "        password = config['mysql']['password'],\n",
    "        database = config['mysql']['database']\n",
    "    )\n",
    "        \n",
    "    return conn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce187950-ba61-43da-b3b2-adcc26f74af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_db(table, field, condition):\n",
    "    \n",
    "    conn = open_connection()\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    cursor.execute(f\"UPDATE {table} SET {field} WHERE {condition};\")\n",
    "\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74186bbb-ce88-48c8-aaf4-6dd0fbda7cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_db(query):\n",
    "    \n",
    "    conn = open_connection()\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    cursor.execute(query)\n",
    "\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2164244a-d491-42c2-bd19-2f62263ce64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_db(query):\n",
    "    conn = open_connection()\n",
    "    \n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    \n",
    "    conn.close()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b340d245-7251-4b01-879e-187a50119290",
   "metadata": {},
   "source": [
    "#### Specific operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d10c8ed-7d8a-4eae-84b3-2c11f7e62584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_control_db(file_type, file_name = False):\n",
    "    \n",
    "    if file_name == False:\n",
    "        \n",
    "        check = read_db(f\"SELECT name FROM control WHERE type ='{file_type}'\").to_dict(orient='records')\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        check = read_db(f\"SELECT name FROM control WHERE type ='{file_type}' AND name = '{file_name}'\").to_dict(orient='records')\n",
    "        \n",
    "        if len(check) > 0:\n",
    "            check = True\n",
    "        else:\n",
    "            check = False\n",
    "\n",
    "    return check"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5562466e-097e-4333-acf7-fa573c188f9b",
   "metadata": {},
   "source": [
    "check_control_db(file_type = 'download')#, file_name = '20221001/20221001235900.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "808f97b8-16b5-45c4-aa8e-5c2f16c7e90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file_db(item_name, file_name, download_folder = 'Downloads', type_control = 'download'):\n",
    "    \n",
    "    path = check_folder(download_folder)\n",
    "    \n",
    "    #query to get information from Mysql about control\n",
    "    check = check_control_db(file_type = type_control, file_name = file_name)\n",
    "                             \n",
    "    #check if the file has been unzipped before\n",
    "    if check == False:\n",
    "    \n",
    "        #getting Itens names\n",
    "        item = internetarchive.get_item(item_name)\n",
    "        \n",
    "        print(f\"Downloading {file_name}\")\n",
    "\n",
    "        #downloading\n",
    "        r = item.download(\n",
    "            destdir=path,  # The directory to download files to\n",
    "            ignore_existing=True,  # Skip files that already exist locally\n",
    "            checksum=True,  # Skip files based on checksum\n",
    "            verbose=False,  # Print progress to stdout\n",
    "            retries=600,  # The number of times to retry on failed requests\n",
    "            no_directory=True,  # Download withtout the identifier\n",
    "            files = file_name)\n",
    "        \n",
    "        #getting Metadata\n",
    "        metadata = list(filter(lambda p: p[\"name\"] == file_name, item.item_metadata['files']))\n",
    "\n",
    "        #Adding file name on control list\n",
    "        dt = datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f')\n",
    "        sz = metadata[0]['size']\n",
    "        query_db(f\"INSERT INTO control (name, datetime, type, size) VALUES ('{file_name}', '{dt}', '{type_control}', '{sz}')\")\n",
    "        \n",
    "        print(f\"{file_name} downloaded\")\n",
    "    \n",
    "        path_file = path + f'/{file_name}'\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        path_file = False   \n",
    "    \n",
    "    return path_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff8a6aea-def3-47d2-b9dc-c85e10ba56f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tar_file_db(tar_file, file_name, extration_folder='Extraction', type_control = 'extraction'):\n",
    "    \n",
    "    path = check_folder(extration_folder)\n",
    "    \n",
    "    #query to get information from Mysql about control\n",
    "    check = check_control_db(file_type = type_control, file_name = file_name)\n",
    "    \n",
    "    #check if the file has been unzipped before\n",
    "    if check == False:    \n",
    "\n",
    "        #Extracting file\n",
    "        tar_file.extract(file_name, path=path)\n",
    "\n",
    "        #Adding file name on control list\n",
    "        dt = datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f')\n",
    "        sz = tar_file.getmember(name=file_name).size\n",
    "        query_db(f\"INSERT INTO control (name, datetime, type, size) VALUES ('{file_name}', '{dt}', '{type_control}', '{sz}')\")\n",
    "        \n",
    "        path_file = path + f'/{file_name}'\n",
    "    \n",
    "    else: #case the file has been unzipped\n",
    "            \n",
    "        path_file = False\n",
    "        \n",
    "    \n",
    "    return path_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ee5629-db75-4b84-9840-753eec3876dc",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccd49266-a8dd-4b4d-9b82-af9f6b2b0492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c48b19e5474a4fa8827d80cf1b9930fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Download progress:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading twitter-stream-20220201.tar\n",
      "twitter-stream-20220201.tar downloaded\n",
      "Unziping twitter-stream-20220201.tar\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e32477418da044ee92ff111c5a0cdcbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unzip progress:   0%|          | 0/1440 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twitter-stream-20220201.tar Unziped\n",
      "Downloading twitter-stream-20220202.tar\n",
      "twitter-stream-20220202.tar downloaded\n",
      "Unziping twitter-stream-20220202.tar\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6460eae06644951b200a8b789017b00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unzip progress:   0%|          | 0/1420 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twitter-stream-20220202.tar Unziped\n",
      "Downloading twitter-stream-20220203.tar\n",
      "twitter-stream-20220203.tar downloaded\n",
      "Unziping twitter-stream-20220203.tar\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b418ae6f2a8431b8c675afd1efcd58a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unzip progress:   0%|          | 0/1419 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twitter-stream-20220203.tar Unziped\n",
      "Downloading twitter-stream-20220204.tar\n",
      "twitter-stream-20220204.tar downloaded\n",
      "Unziping twitter-stream-20220204.tar\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4c91164d2f146b49cb10682cac1697b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unzip progress:   0%|          | 0/1440 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twitter-stream-20220204.tar Unziped\n",
      "Downloading twitter-stream-20220205.tar\n",
      "twitter-stream-20220205.tar downloaded\n",
      "Unziping twitter-stream-20220205.tar\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bdae8bb95de469d931cbf0ba97c667f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unzip progress:   0%|          | 0/1440 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twitter-stream-20220205.tar Unziped\n",
      "Downloading twitter-stream-20220206.tar\n",
      "twitter-stream-20220206.tar downloaded\n",
      "Unziping twitter-stream-20220206.tar\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5a905c0319c4859bf74943fff0a9291",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unzip progress:   0%|          | 0/1440 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twitter-stream-20220206.tar Unziped\n",
      "Downloading twitter-stream-20220207.tar\n",
      "twitter-stream-20220207.tar downloaded\n",
      "Unziping twitter-stream-20220207.tar\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8507f5d7ed354084aec787344fbf62c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unzip progress:   0%|          | 0/1439 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twitter-stream-20220207.tar Unziped\n",
      "Downloading twitter-stream-20220208.tar\n",
      "twitter-stream-20220208.tar downloaded\n",
      "Unziping twitter-stream-20220208.tar\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3dd91d0e7ad4d83b1d98ea8a7e85f79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unzip progress:   0%|          | 0/1440 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twitter-stream-20220208.tar Unziped\n",
      "Downloading twitter-stream-20220209.tar\n",
      "twitter-stream-20220209.tar downloaded\n",
      "Unziping twitter-stream-20220209.tar\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e3a79710eec4703a22d094a1185cef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unzip progress:   0%|          | 0/1440 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twitter-stream-20220209.tar Unziped\n",
      "Downloading twitter-stream-20220210.tar\n",
      "twitter-stream-20220210.tar downloaded\n",
      "Unziping twitter-stream-20220210.tar\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4cff33ce2e546088b8a368dbc48acac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unzip progress:   0%|          | 0/1421 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twitter-stream-20220210.tar Unziped\n",
      "Downloading twitter-stream-20220211.tar\n",
      "twitter-stream-20220211.tar downloaded\n",
      "Unziping twitter-stream-20220211.tar\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38316bc586b84d2f8d4aa9d01c85062e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unzip progress:   0%|          | 0/1439 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twitter-stream-20220211.tar Unziped\n",
      "Downloading twitter-stream-20220212.tar\n",
      "twitter-stream-20220212.tar downloaded\n",
      "Unziping twitter-stream-20220212.tar\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af3d19d205d240ec9768afdaf0c99824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unzip progress:   0%|          | 0/1440 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twitter-stream-20220212.tar Unziped\n",
      "Downloading twitter-stream-20220213.tar\n",
      "twitter-stream-20220213.tar downloaded\n",
      "Unziping twitter-stream-20220213.tar\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f664839b0c934bf8a908f0092f2d82b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unzip progress:   0%|          | 0/1440 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twitter-stream-20220213.tar Unziped\n",
      "Downloading twitter-stream-20220214.tar\n",
      "twitter-stream-20220214.tar downloaded\n",
      "Unziping twitter-stream-20220214.tar\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05d6f5615e234a53bdc02e89e476f66a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unzip progress:   0%|          | 0/1440 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twitter-stream-20220214.tar Unziped\n",
      "Downloading twitter-stream-20220215.tar\n",
      "twitter-stream-20220215.tar downloaded\n",
      "Unziping twitter-stream-20220215.tar\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae55a26078734be38f5d581e90a6e2a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unzip progress:   0%|          | 0/1421 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twitter-stream-20220215.tar Unziped\n",
      "Downloading twitter-stream-20220216.tar\n",
      "twitter-stream-20220216.tar downloaded\n",
      "Unziping twitter-stream-20220216.tar\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f15bc1542fba4dcf88e3baeb70663869",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unzip progress:   0%|          | 0/1429 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twitter-stream-20220216.tar Unziped\n",
      "Downloading twitter-stream-20220217.tar\n",
      "twitter-stream-20220217.tar downloaded\n",
      "Unziping twitter-stream-20220217.tar\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "863a1bf08f47419bae2f28779679b11a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unzip progress:   0%|          | 0/1439 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twitter-stream-20220217.tar Unziped\n",
      "Downloading twitter-stream-20220218.tar\n",
      "twitter-stream-20220218.tar downloaded\n",
      "Unziping twitter-stream-20220218.tar\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d83cdaacd051418da83fa584d58e1705",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unzip progress:   0%|          | 0/1440 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twitter-stream-20220218.tar Unziped\n",
      "Downloading twitter-stream-20220219.tar\n",
      "twitter-stream-20220219.tar downloaded\n",
      "Unziping twitter-stream-20220219.tar\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09bafdbf3ad74a5fa148e487a7e63893",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unzip progress:   0%|          | 0/1440 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twitter-stream-20220219.tar Unziped\n",
      "Downloading twitter-stream-20220220.tar\n",
      "twitter-stream-20220220.tar downloaded\n",
      "Unziping twitter-stream-20220220.tar\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8f0be00aab8470a9fa665c10edb4684",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unzip progress:   0%|          | 0/1440 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twitter-stream-20220220.tar Unziped\n",
      "Downloading twitter-stream-20220221.tar\n",
      "twitter-stream-20220221.tar downloaded\n",
      "Unziping twitter-stream-20220221.tar\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2cf36ab5e174e5fa9e7a9f2d91c2cf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unzip progress:   0%|          | 0/1440 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twitter-stream-20220221.tar Unziped\n",
      "Downloading twitter-stream-20220222.tar\n",
      "twitter-stream-20220222.tar downloaded\n",
      "Unziping twitter-stream-20220222.tar\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea85b1fb585449258eb06e81d70ed608",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unzip progress:   0%|          | 0/1386 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twitter-stream-20220222.tar Unziped\n",
      "Downloading twitter-stream-20220223.tar\n",
      "twitter-stream-20220223.tar downloaded\n",
      "Unziping twitter-stream-20220223.tar\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bed79bf1ff440a79d070393f6e40b32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unzip progress:   0%|          | 0/1416 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twitter-stream-20220223.tar Unziped\n",
      "Downloading twitter-stream-20220224.tar\n",
      "twitter-stream-20220224.tar downloaded\n",
      "Unziping twitter-stream-20220224.tar\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1f83cdb88634e0a942ae9c1db97e025",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unzip progress:   0%|          | 0/1439 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twitter-stream-20220224.tar Unziped\n",
      "Downloading twitter-stream-20220225.tar\n",
      "twitter-stream-20220225.tar downloaded\n",
      "Unziping twitter-stream-20220225.tar\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4fcedaf05cd40bd968fd4ae69fe4251",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unzip progress:   0%|          | 0/1438 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twitter-stream-20220225.tar Unziped\n",
      "Downloading twitter-stream-20220226.tar\n",
      "twitter-stream-20220226.tar downloaded\n",
      "Unziping twitter-stream-20220226.tar\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "341249a5e69e4aab9a1de7dfef14b516",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unzip progress:   0%|          | 0/1440 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twitter-stream-20220226.tar Unziped\n",
      "Downloading twitter-stream-20220227.tar\n",
      "twitter-stream-20220227.tar downloaded\n",
      "Unziping twitter-stream-20220227.tar\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92bafeb2a4314cb1ac5f72ee363500d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unzip progress:   0%|          | 0/1440 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twitter-stream-20220227.tar Unziped\n",
      "Downloading twitter-stream-20220228.tar\n",
      "twitter-stream-20220228.tar downloaded\n",
      "Unziping twitter-stream-20220228.tar\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58a99d3fae08441fa07522984f5f99a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unzip progress:   0%|          | 0/1439 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twitter-stream-20220228.tar Unziped\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "item_name = 'archiveteam-twitter-stream-2022-02'\n",
    "\n",
    "#Getting Itens names\n",
    "file_names = get_file_name(item_name = item_name)#, ext = '*jpg')\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    for dlf in tqdm(file_names, desc='Download progress'):\n",
    "\n",
    "        #downloading the file\n",
    "        file_future = executor.submit(download_file_db, item_name=item_name, file_name=dlf)\n",
    "\n",
    "        if not file_future.result() == False:\n",
    "\n",
    "            #Open tar file\n",
    "            tar = tarfile.open(file_future.result(), \"r\")\n",
    "\n",
    "            #Getting json files' names\n",
    "            tar_file_names = list(filter(lambda t: t.endswith('.json.gz'), tar.getnames()))\n",
    "\n",
    "            print(f\"Unziping {dlf}\")\n",
    "            \n",
    "            for tf in tqdm(tar_file_names, desc='Unzip progress'):\n",
    "\n",
    "                #call funcition to extract files\n",
    "                js_future = executor.submit(tar_file_db, tar_file=tar, file_name=tf)\n",
    "\n",
    "                #if the file has already been unzipped that part will be skipped\n",
    "                if not js_future.result() == False:\n",
    "\n",
    "                    #Getting, cleaning and storing Data\n",
    "                    bow = ['vaccination', 'vaccines', 'vaccine']\n",
    "                    df = get_data(file_path = js_future.result(), file_name = tf, lang = 'en', word_bag = bow, db_update = True)\n",
    "\n",
    "                    if not df.empty:\n",
    "\n",
    "                        conn = open_connection()\n",
    "                        cursor = conn.cursor()\n",
    "\n",
    "                        for index, row in df.iterrows():\n",
    "                            created_at = row['created_at']\n",
    "                            text = row['text']\n",
    "                            entities = json.dumps(row['entities'])\n",
    "\n",
    "                            sql = \"INSERT INTO tweets (created_at, text, entities) VALUES (%s, %s, %s)\"\n",
    "                            cursor.execute(sql, (created_at, text, entities))\n",
    "\n",
    "                            conn.commit()\n",
    "\n",
    "                        cursor.close()\n",
    "                        conn.close()\n",
    "\n",
    "                    #deleting json file after processing\n",
    "                    os.remove(js_future.result())\n",
    "\n",
    "            print(f\"{dlf} Unziped\")\n",
    "            \n",
    "            #closing tar file\n",
    "            tar.close()\n",
    "\n",
    "            #x =+ 1\n",
    "\n",
    "            #removing file downloaded\n",
    "            os.remove(file_future.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95132611-4008-4a35-9de6-05c7f4e766e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a6291b-6142-49be-9799-d7eab06dc00c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2542e50a-a91f-4c49-9889-0fb34e855bcf",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf51442-8748-4e3c-b482-5b232b09dcd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243e2b02-ac8f-481d-a2b9-8781bcb5085e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6985f02c-fd5f-417f-a3a3-c90b42a7f823",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a95354-d191-4f9e-8c54-f0862a54bde4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-autonumbering": true,
  "toc-showcode": true,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
